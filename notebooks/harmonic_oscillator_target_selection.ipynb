{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1ce48-fac3-4d7c-8985-c7a7fda1131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test script that puts it all together\n",
    "import os\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4369abc-43c4-4264-94ef-af8f5f29d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31085e-a4a7-463e-8773-0bec7373f3bd",
   "metadata": {},
   "source": [
    "### Optimal Behaviour and User Modelling\n",
    "\n",
    "Optimal user behaviour reduces a target's energy most rapidly. This involves exactly tracking the target's position, instantly absorbing all potential energy as it is converted from kinetic energy. In practice real users have constraint precision and act with delays, both present in their visual perception, cognitive process, and motor execution. To capture delays and constraint precision, we model user input as a first-order lag with Gaussian noise.\n",
    "\n",
    "#### First Order Lag User\n",
    "\n",
    "A first order lag system receives a repeated step function control signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965a147-6768-4940-82a7-8152fda21b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# control signal u\n",
    "num_repetitions = 3\n",
    "num_steps_per_phase = 10\n",
    "u = np.hstack([np.zeros((num_repetitions, num_steps_per_phase)), np.ones((num_repetitions, num_steps_per_phase))]).reshape(-1)\n",
    "plt.plot(u, label='u')\n",
    "plt.title('control signal');\n",
    "plt.xlabel('timestep t (int)');\n",
    "\n",
    "# lag response\n",
    "k = 0.5 # lag constant [0, 1]\n",
    "y = np.zeros_like(u)\n",
    "y[0] = 0\n",
    "for t in range(1, u.shape[0]):\n",
    "  y[t] = (1-k) * y[t-1] + k * u[t]\n",
    "  \n",
    "plt.plot(y, label='y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f639116-c005-43f6-9797-d7b2ccb80a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Wrap behavior in an agent class.\n",
    "class FirstOrderLag:\n",
    "  \"\"\"\"\n",
    "  First order lag (vectorized).\n",
    "  \n",
    "  Args:\n",
    "      conductivity (np.array): moving average weight of new input, in [0,1].\n",
    "      s0 (np.array): initial state after reset. \n",
    "      bounds (np.array): minimum and maximum state values\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, conductivity=0.5, s0=0, bounds=None):\n",
    "    self.k = conductivity\n",
    "    self.s0 = s0\n",
    "    self.bounds = bounds\n",
    "    \n",
    "  def copy(self):\n",
    "    other = FirstOrderLag(conductivity=self.k,\n",
    "                          s0=self.s0,\n",
    "                          bounds=self.bounds)\n",
    "    other.s = self.s.copy()\n",
    "    return other\n",
    "    \n",
    "  def reset(self):\n",
    "    self.s = np.copy(self.s0)\n",
    "    self.s = self._clip(self.s)\n",
    "    return {'x': self.s, 'dx': np.zeros_like(self.s)}\n",
    "  \n",
    "  def step(self, u):\n",
    "    s = (1-self.k) * self.s + self.k * u\n",
    "    s = self._clip(s)\n",
    "    ds = s - self.s\n",
    "    self.s = s\n",
    "    return {'x': self.s, 'dx': ds}\n",
    "  \n",
    "  def _clip(self, s):\n",
    "    if self.bounds is None:\n",
    "      return s\n",
    "    \n",
    "    return np.clip(s, self.bounds[0], self.bounds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c738fe-a124-41b9-a26b-82ee8489d614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. simulate agent response to control signal.\n",
    "user = FirstOrderLag(conductivity=0.15)\n",
    "y = [user.reset()] + [user.step(u[t]) for t in range(1, u.shape[0])]\n",
    "plt.plot(u, label='target')\n",
    "plt.plot([y['x'] for y in y], label='lag')\n",
    "plt.plot([y['dx'] for y in y], label='$\\Delta$lag')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb40a5-7d68-46e6-9f12-afddecfa04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug copy constructor\n",
    "lag_new = user.copy()\n",
    "y_new = [lag_new.step(u[t]) for t in range(u.shape[0]-10)]\n",
    "y_old = [user.step(u[t]) for t in range(u.shape[0]-10)]\n",
    "plt.plot([y['x'] for y in y_new], label='lag (new)')\n",
    "plt.plot([y['x'] for y in y_old], label='lag (old)')\n",
    "plt.plot([y['dx'] for y in y_new], label='$\\Delta$lag (new)')\n",
    "plt.plot([y['dx'] for y in y_old], label='$\\Delta$lag (old)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab7a31-b79b-4d69-98ad-28cb33e930da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Interface\n",
    "\n",
    "To illustrate how active inference can help adapt parameters of complex user interfaces to improve performance, we explore a target selection task with artificially complicated but well understood interaction dynamics. A visual display shows $N$ targets in motion mimicking the harmonic oscillation of masses on springs. All springs are *anchored* at the same height to a horizontal line that is controlled by the user. Each target has a different parametrization corresponding to different oscillation frequencies. A target is selected by reducing its mechanical energy to fall below some threshold $\\tau$ while keeping all other targets' mechanical energies above the threshold. The mechanical energy is defined as the sum of potential energy and kinetic energy, with all energy being kinetic at the zero crossing and all energy being potential at the oscillation extrema. The oscillation amplitude thereby gives the user feedback about the effect of their inputs on progress towards selecting individual targets. Moving the anchor towards or away from a target reduces or increase its potential energy, respectively.\n",
    "\n",
    "The harmonic oscillators act as a common mediating mechanism between various input spaces (e.g., trajectories of a mouse pointer, a visually tracked hand, gaze, or device tilting movements) and the control space (one of $N$ target selection). By decoupling the interaction metaphor from the specific input modality we can leverage users' mental model of the dynamics to make control across multiple modalities more intuitive, provided that parametrisations of the dynamics can be found that work well for each modality and user. Traditionally, finding good parametrisations was done manually or through trial and error user testing in each new context. More recently, computational interaction methods have been proposed, where user models trained via reinforcement learning are used to evaluate individual interface parametrisations in simulation  off-line. Here, we set out to demonstrate how active inference can be used to simultaneously learn the user model and adapt interface parametrisations to optimize task performance on-line, i.e. while a user interacts with the system.\n",
    "\n",
    "### Harmonic Oscillators\n",
    "\n",
    "We parametrise each harmonic oscillator with a mass $m$ and a spring constant $\\kappa$, which correspond to the oscillation frequency in Eq. X\n",
    "$$f=\\frac{1}{2\\pi}\\sqrt{\\frac{\\kappa}{m}}$$\n",
    "\n",
    "The state is represented by $(x, \\dot x)$ , where $x$ is its distance from the anchor and $\\dot x$ its velocity. The mechanical energy $E$, potential energy $U$, and kinetic energy $K$ are defined as in Eq. X\n",
    "$$\n",
    "E = U + K \n",
    "$$\n",
    "$$ U = \\frac{1}{2}\\kappa \\cdot x^2 $$\n",
    "$$ K = \\frac{1}{2}m \\cdot \\dot x^2 $$\n",
    "\n",
    "The dynamics are described by an ordinary differential equation (ODE) and state updates are performed by taking one Euler step of length $\\delta t$ (see Eq. X)\n",
    "\n",
    "$$ \\ddot x = \\frac{F}{m} = \\frac{-\\kappa \\cdot \\dot x_t}{m} $$\n",
    "$$ \\dot x_t = \\dot x_{t-1} + \\delta t \\cdot \\ddot x_t $$\n",
    "$$ x_t = x_{t-1} + \\delta t \\cdot \\ \\dot x_t$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd990fd-cb59-4afe-bfda-f08d99259755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarmonicOscillator():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 N=1, \n",
    "                 mass=1., \n",
    "                 spring_constant=1., \n",
    "                 damping_coefficient=0., \n",
    "                 dt=0.1, \n",
    "                 energy_start=1., \n",
    "                 energy_max=2):\n",
    "      self.N = N\n",
    "      self.mass_start = mass\n",
    "      self.spring_start = spring_constant\n",
    "      self.damping_start = damping_coefficient\n",
    "      self.dt = dt # Euler step length\n",
    "      self.energy_start = energy_start\n",
    "      self.energy_max = energy_max\n",
    "      \n",
    "      self.x = None\n",
    "      self.v = None\n",
    "      self.anchor = 0\n",
    "      \n",
    "    def copy(self):\n",
    "      other = HarmonicOscillator(N=self.N,\n",
    "                                 mass=self.mass_start,\n",
    "                                 spring_constant=self.spring_start,\n",
    "                                 damping_coefficient=self.damping_start,\n",
    "                                 dt=self.dt,\n",
    "                                 energy_start=self.energy_start,\n",
    "                                 energy_max=self.energy_max)\n",
    "      other.mass = self.mass.copy()\n",
    "      other.spring = self.spring.copy()\n",
    "      other.damping = self.damping.copy()\n",
    "      other.x = self.x.copy()\n",
    "      other.v = self.v.copy()\n",
    "      other.anchor = self.anchor\n",
    "      return other               \n",
    "      \n",
    "    def frequency(self):\n",
    "      return 1/(2*np.pi) * np.sqrt(self.spring / self.mass)\n",
    "    \n",
    "    def set_frequency(self, f):\n",
    "      ratio = (2*np.pi*f)**2\n",
    "      self.spring = ratio * self.mass_start\n",
    "      \n",
    "    def set_energy(self, energy):\n",
    "      u = self.potential_energy()\n",
    "      k = self.kinetic_energy()\n",
    "      e = u + k\n",
    "      factor = energy/e\n",
    "      u_target = u * factor\n",
    "      self.x = np.sqrt(2 * u_target / self.spring) * np.sign(self.x)\n",
    "      k_target = k * factor\n",
    "      self.v = np.sqrt(2 * k_target / self.mass) * np.sign(self.v)\n",
    "    \n",
    "    def potential_energy(self, x=None, spring=None):\n",
    "      x = self.x if x is None else x\n",
    "      spring = self.spring if spring is None else spring\n",
    "      return 0.5 * spring * (x - self.anchor)**2\n",
    "    \n",
    "    def kinetic_energy(self, v=None, mass=None):\n",
    "      v = self.v if v is None else v\n",
    "      mass = self.mass if mass is None else mass\n",
    "      return 0.5 * mass * v**2\n",
    "    \n",
    "    def energy(self, x=None, v=None, spring=None, mass=None):\n",
    "      return self.potential_energy(x, spring) + self.kinetic_energy(v, mass)\n",
    "    \n",
    "    def ddot_x(self, dx, v=None, spring=None, damping=None, mass=None):\n",
    "      v = self.v if v is None else v\n",
    "      spring = self.spring if spring is None else spring\n",
    "      damping = self.damping if damping is None else damping\n",
    "      mass = self.mass if mass is None else mass\n",
    "      \n",
    "      f_spring = -spring * dx # reduced spring should reduce spring force\n",
    "      f_friction = -damping * v\n",
    "      f_total = f_spring + f_friction\n",
    "      a = f_total / mass # reduced mass should increase acceleration\n",
    "      return a\n",
    "    \n",
    "    def reset(self):\n",
    "      # self.anchor = self.anchor_start\n",
    "      self.mass = self.mass_start * np.ones(self.N)\n",
    "      self.spring = self.spring_start * np.ones(self.N)\n",
    "      self.damping = self.damping_start * np.ones(self.N)\n",
    "      \n",
    "      # initialise all targets with equal energy and different phase\n",
    "      phase = np.linspace(0, 2*np.pi, self.N+1)[:-1]\n",
    "      e = self.energy_start # total mechanical energy\n",
    "      max_x = np.sqrt(2*e/self.spring) # amplitude along x\n",
    "      self.x = max_x * np.sin(phase) + self.anchor\n",
    "      # note: maximum avoids numerical instability near zero in sqrt\n",
    "      k = np.maximum(0, e - self.potential_energy())\n",
    "      self.v = np.sqrt(2*k/self.mass) * np.sign(np.cos(phase))\n",
    "      return {'x': self.x, 'v': self.v, \n",
    "              'debug': {'energy': self.energy(), 'mass': self.mass, 'spring': self.spring}\n",
    "              }\n",
    "    \n",
    "    def step(self, action=0):\n",
    "      # make hypothetical step with original parameters\n",
    "      self.anchor = action\n",
    "      dx = self.x - self.anchor\n",
    "      a = self.ddot_x(dx)\n",
    "      v = self.v + self.dt * a\n",
    "      x = self.x + self.dt * v\n",
    "\n",
    "      # boundary condition: limit energy\n",
    "      e = self.energy(x=x, v=v)\n",
    "      factor = np.minimum(1, self.energy_max / e)\n",
    "      # re-estimate step with scaled parameters\n",
    "      spring = self.spring * factor\n",
    "      mass = self.mass * factor\n",
    "      a = self.ddot_x(dx, spring=spring, mass=mass)\n",
    "      self.v = self.v + self.dt * a\n",
    "      self.x = self.x + self.dt * self.v\n",
    "\n",
    "      return {'x': self.x, 'v': self.v, \n",
    "              'debug': {'energy': self.energy(spring=spring, mass=mass), 'mass': mass, 'spring': spring}\n",
    "             }\n",
    "    \n",
    "    def plot_phase_space(self, axis=None):\n",
    "      if axis is None:\n",
    "        _, axis = plt.subplots()\n",
    "      num_steps = int(np.max(1/(self.frequency() * self.dt))) + 2\n",
    "      outputs = ['x', 'v']\n",
    "      if self.x is None:\n",
    "        self.reset()\n",
    "      \n",
    "      states = {o: [] for o in outputs}\n",
    "      for _ in range(num_steps):\n",
    "        state = self.step()\n",
    "        for o in outputs:\n",
    "          states[o].append(state[o])\n",
    "      \n",
    "      plt.sca(axis)\n",
    "      plt.plot(np.array(states['x']), np.array(states['v']), '-')\n",
    "      plt.title('Phase space');\n",
    "      plt.xlabel('$x$')\n",
    "      plt.ylabel(\"$\\dot x$\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994670f-4937-4539-a9c0-4e8a70469b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. simulate uncontrolled MassSpringDamper\n",
    "num_steps = 200\n",
    "agent = HarmonicOscillator(N=1, dt=0.1, energy_start=3e3, energy_max=6e3)\n",
    "agent.reset()\n",
    "agent.plot_phase_space()\n",
    "\n",
    "os = [agent.reset()]\n",
    "for i in range(num_steps):\n",
    "  if i > 100:\n",
    "    # change frequency\n",
    "    f = agent.frequency()\n",
    "    e = agent.energy()\n",
    "    # change energy\n",
    "    agent.set_frequency(f*1.05)\n",
    "    agent.set_energy(e)\n",
    "    #agent.set_energy(e*0.99)\n",
    "    #agent.plot_phase_space(axis=plt.gca())\n",
    "    #print(e, '->', agent.energy())\n",
    "    \n",
    "  os.append(agent.step())\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(2*6, 12))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.title('absolute position over time')\n",
    "xs = [o['x'] for o in os]\n",
    "plt.plot(xs)\n",
    "plt.ylabel('position')\n",
    "plt.xlabel('timestep t')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.title('energy over time')\n",
    "es = [o['debug']['energy'] for o in os]\n",
    "plt.plot(es)\n",
    "plt.ylabel('E')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylim([0, np.max(es)]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ead646-40fd-49d8-b10a-bb60728d5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug copy constructor\n",
    "ho = agent.copy()\n",
    "ys_new = [ho.step(10)['x'] for _ in range(50)]\n",
    "ys_old = [agent.step()['x'] for _ in range(50)]\n",
    "plt.plot(ys_new)\n",
    "plt.plot(ys_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbb2bb-f8b0-4c46-84f6-8672cbcd2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate dynamics of oscillators with different parameters and different energy\n",
    "num_objects = 5\n",
    "mass = np.hstack([ 1 * np.ones((num_objects)), 3 * np.ones(num_objects)]).reshape(-1)\n",
    "spring = np.hstack([ 3 * np.ones((num_objects)), 1 * np.ones(num_objects)]).reshape(-1)\n",
    "agent = HarmonicOscillator(N=2*num_objects, mass=mass, spring_constant=spring)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(2*6, 6))\n",
    "agent.reset()\n",
    "agent.plot_phase_space(axes[0])\n",
    "\n",
    "xs = [agent.reset()['x']]\n",
    "for _ in range(num_steps):\n",
    "  xs.append(agent.step()['x'])\n",
    "  \n",
    "plt.sca(axes[-1])\n",
    "plt.plot(xs);\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be2889-2eed-42d0-bf4e-1392b76a4b3e",
   "metadata": {},
   "source": [
    "# User-UI Interaction\n",
    "\n",
    "## Single object to control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021a3dd-05d3-439a-b9b8-35cda1f7d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "  \"\"\" Gaussian agent. Adds Gaussian noise to its input. \"\"\"\n",
    "  def __init__(self, rng, stdev=1., a0=0, mode='additive'):\n",
    "    self.rng = rng\n",
    "    self.stdev = stdev\n",
    "    self.a0 = a0 # assumed starting input\n",
    "    self.mode = mode # {'additive', 'scaled'}\n",
    "\n",
    "    self.sample = self._sample_additive\n",
    "    if self.mode == 'multiply':\n",
    "      self.sample = self._sample_multiplicative\n",
    "    \n",
    "  def reset(self):\n",
    "    return self.sample(self.a0)\n",
    "  \n",
    "  def step(self, a):\n",
    "    return self.sample(a)\n",
    "  \n",
    "  def _sample_additive(self, a):\n",
    "    return a + self.rng.normal(size=np.asarray(a).shape) * self.stdev\n",
    "  \n",
    "  def _sample_multiplicative(self, a):\n",
    "    return a * self.rng.normal(size=np.asarray(a).shape) * self.stdev\n",
    "\n",
    "  \n",
    "gaussian = Gaussian(rng=rng, stdev=0.1, a0=0, mode='multiply')\n",
    "xs = [gaussian.step(i*0.01) for i in range(10000)]\n",
    "plt.plot(xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b502ab3-122e-4570-be2a-02ef7c10b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLag:\n",
    "  \"\"\" \n",
    "  First-order lag on noisy observations. \n",
    "  Used as a model for user input. \n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, noise, lag):\n",
    "    self.noise = noise\n",
    "    self.lag = lag\n",
    "    \n",
    "  def reset(self):\n",
    "    # treat lag value as noisy observation of the state\n",
    "    x = self.lag.reset()['x']\n",
    "    x_noisy = self.noise.step(x)\n",
    "    self.lag.s = x_noisy\n",
    "    return {'x': x_noisy, 'dx': 0}\n",
    "    \n",
    "  def step(self, action):\n",
    "    # noisy percept of true position\n",
    "    x_noisy = self.noise.step(action)\n",
    "    # tracking perceived position\n",
    "    return self.lag.step(x_noisy)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14920730-c958-477a-9d6a-915eb7bffbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. simulate MassSpringDamper controlled by FirstOrderLag\n",
    "num_steps = 200\n",
    "\n",
    "ui = HarmonicOscillator(energy_start=3e3, energy_max=6e3)\n",
    "# generate an uncontrolled sequence\n",
    "ui.reset()\n",
    "xs = [ui.reset()['x']] + [ui.step()['x'] for _ in range(num_steps)]\n",
    "\n",
    "# close the loop with a first-order lag user\n",
    "user_lag = FirstOrderLag(conductivity=0.2)\n",
    "user_noise = Gaussian(stdev=10.)\n",
    "user = NoisyLag(lag=user_lag, noise=user_noise)\n",
    "user.reset()\n",
    "os_user = []\n",
    "os_ui = [ui.reset()]\n",
    "for i in range(num_steps):\n",
    "  # user response to UI stimulus\n",
    "  o_user = user.step(os_ui[-1]['x'])\n",
    "  os_user.append(o_user)\n",
    "  \n",
    "  # UI update in response to user\n",
    "  os_ui.append(ui.step(o_user['x']))\n",
    "  \n",
    "plt.plot(xs, label='uncontrolled system')\n",
    "plt.plot([o['x'] for o in os_user], label='control signal')\n",
    "plt.plot([o['x'] for o in os_ui], label='controlled system')\n",
    "plt.title('absolute position over time')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61ed4a-9df2-4ce6-9d29-a58106443d25",
   "metadata": {},
   "source": [
    "## Selective control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee36ae-abc9-4899-a631-95c5671bb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. simulate a set of MassSpringDampers with different mass and selective control with FirstOrderLag\n",
    "num_targets = 8\n",
    "num_steps = 200\n",
    "user_target = 1\n",
    "\n",
    "ui = HarmonicOscillator(N=num_targets, energy_start=3e3, energy_max=6e3)\n",
    "# generate an uncontrolled sequence\n",
    "ui.reset()\n",
    "xs_uncontrolled = [ui.reset()['x']] + [ui.step()['x'] for _ in range(num_steps)]\n",
    "\n",
    "# close the loop with a first-order lag user\n",
    "user_lag = FirstOrderLag(conductivity=0.2)\n",
    "user_noise = Gaussian(stdev=10.)\n",
    "user = NoisyLag(lag=user_lag, noise=user_noise)\n",
    "user.reset()\n",
    "os_user = []\n",
    "os_ui = [ui.reset()]\n",
    "for i in range(num_steps):\n",
    "  # user response to UI stimulus\n",
    "  o_user = user.step(os_ui[-1]['x'][user_target])\n",
    "  os_user.append(o_user)\n",
    "  # UI update in response to user\n",
    "  os_ui.append(ui.step(o_user['x']))\n",
    "  \n",
    "fig, ax = plt.subplots(2, 1, figsize=(2*6, 12))\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.title('Position over time')\n",
    "xs = [o['x'] for o in os_ui]\n",
    "plt.plot(xs)\n",
    "plt.plot(np.array(xs_uncontrolled)[:,user_target], 'r--', label='uncontrolled system')\n",
    "plt.plot([o['x'] for o in os_user], label='control signal')\n",
    "plt.plot(np.array(xs)[:,user_target], 'r', label='controlled system')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('absolute position')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.title('Energy over time')\n",
    "es = [o['debug']['energy'] for o in os_ui]\n",
    "plt.plot(es)\n",
    "plt.plot(np.array(es)[:,user_target], 'r')\n",
    "plt.ylabel('mechanical energy E')\n",
    "plt.xlabel('timestep t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745135c-7377-4862-8e3f-7df8b02c96f8",
   "metadata": {},
   "source": [
    "## Selection Trigger (naive)\n",
    "\n",
    "As the number of targets increases\n",
    "- the threshold needs lowered\n",
    "- the EMA conductivity needs to be reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b4e10-1833-4d9f-8120-3e1fbf5ebc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential moving average (first-order lag)\n",
    "\n",
    "energy_start = ui.energy_start\n",
    "threshold = 0.2*energy_start\n",
    "ema = FirstOrderLag(conductivity=0.2, s0 = np.ones_like(es[0]) * energy_start)\n",
    "es_ema = [ema.reset()['x']] + [ema.step(E)['x'] for E in es]\n",
    "selection = [y < threshold for y in es_ema]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "plt.plot([0, len(xs)], [threshold]*2, 'r--', label='threshold')\n",
    "plt.plot(es_ema)\n",
    "plt.plot(np.array(es_ema)[:,user_target], 'r-', label='controlled system', linewidth=3)\n",
    "plt.plot(np.array(selection)*2*energy_start, 'k', linewidth=1);\n",
    "plt.legend()\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('smoothed energy EMA(E)')\n",
    "plt.title('smoothed energy over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009cb7b0-6d77-470f-bb01-e0e439eb8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User target generator\n",
    "class TargetGenerator():\n",
    "  \n",
    "  def __init__(self, num_targets, rng):\n",
    "    self.num_targets = num_targets\n",
    "    self.rng = rng\n",
    "    \n",
    "  def copy(self):\n",
    "    other = TargetGenerator(num_targets=self.num_targets,\n",
    "                           rng=self.rng)\n",
    "    other.s = self.s\n",
    "    other.s_one_hot = self.s_one_hot.copy()\n",
    "    return other\n",
    "    \n",
    "  def reset(self):\n",
    "    self.assign(rng.choice(self.num_targets))\n",
    "    return self.observation()\n",
    "  \n",
    "  def assign(self, target):\n",
    "    self.s = target\n",
    "    self.s_one_hot = np.eye(self.num_targets)[self.s]\n",
    "  \n",
    "  def step(self, trigger_out):\n",
    "    # reset if true positive\n",
    "    if trigger_out.sum() > 0 and trigger_out[self.s]:\n",
    "      return self.reset()\n",
    "    \n",
    "    return self.observation()\n",
    "  \n",
    "  def observation(self):\n",
    "    return {'s': self.s, 's_one_hot': self.s_one_hot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f1bd2-25f6-490f-bc85-6ae344ae5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Register:\n",
    "  \"\"\" Register agent. Updates the state when action is not None and returns the\n",
    "      last state on each step.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, s0=0, bounds=None):\n",
    "    self.s0 = s0\n",
    "    self.bounds = bounds\n",
    "    self.s = None # state\n",
    "    \n",
    "  def reset(self):\n",
    "    self.s = self.s0\n",
    "    self._clip()\n",
    "    return self.s\n",
    "    \n",
    "  def step(self, action=None):\n",
    "    if action is not None:\n",
    "      self.s = action\n",
    "      \n",
    "    self._clip()\n",
    "    return self.s\n",
    "  \n",
    "  def _clip(self):\n",
    "    if self.bounds is None:\n",
    "      return\n",
    "    \n",
    "    self.s = np.clip(self.s, self.bounds[0], self.bounds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595424bb-e3a1-4a49-9413-2eeeb5db6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous observation active inference agent\n",
    "# a. Belief Update agent\n",
    "\n",
    "class BayesianObserver:\n",
    "  \n",
    "  def __init__(self, model, q0_target, q0_conductivity, rng):\n",
    "    # set initial belief\n",
    "    self.model = model\n",
    "    self.q0_target = q0_target\n",
    "    self.q0_conductivity = q0_conductivity\n",
    "    self.rng = rng\n",
    "    self.q = None\n",
    "    \n",
    "  def copy(self):\n",
    "    other = BayesianObserver(model=self.model,\n",
    "              q0_target=self.q0_target,\n",
    "              q0_conductivity=self.q0_conductivity,\n",
    "              rng=rng)\n",
    "    \n",
    "    other.q = self.q.copy()\n",
    "    return other\n",
    "  \n",
    "  def reset(self):\n",
    "    # model is assumed to be stateless self.model.reset()\n",
    "    self.q = np.outer(self.q0_conductivity, self.q0_target)\n",
    "    return {'target': self.q.sum(axis=0), 'conductivity': self.q.sum(axis=1)}\n",
    "            \n",
    "  def step(self, action):\n",
    "    # update user model to synchronise with observation\n",
    "    o = self.model.get_probabilities(action)\n",
    "    p_switch = o['p_switch']\n",
    "    p_o_given_s = o['p_o_given_s']\n",
    "    \n",
    "    # update belief through time\n",
    "    # - assume there is some chance that the user has switched their goal\n",
    "    # - create joint of prior over targets and belief over conductivity\n",
    "    q_marginal_conductivity = self.q.sum(axis=1)\n",
    "    q_switch = np.outer(q_marginal_conductivity, self.q0_target)\n",
    "    self.q = p_switch*q_switch + (1-p_switch)*self.q\n",
    "    # update belief from updated user model\n",
    "    self.q = self._update_belief(p_o_given_s)\n",
    "    return {'target': self._marginal_target(), \n",
    "            'conductivity': self._marginal_conductivity()}\n",
    "  \n",
    "  def sample(self):\n",
    "    k_index = self.rng.choice(self.q.shape[0], p=self._marginal_conductivity())\n",
    "    i = self.rng.choice(self.q.shape[1], p=self._conditional_target(k_index))\n",
    "    p = self.joint_probability(target=i, conductivity_index=k_index)\n",
    "    return {'target': i, \n",
    "            'conductivity_index': k_index,\n",
    "            'conductivity': self.model.k[k_index], \n",
    "            'p': p}\n",
    "    \n",
    "  def joint_probability(self, target, conductivity_index):\n",
    "    return self.q[conductivity_index, target]\n",
    "\n",
    "  def _marginal_target(self):\n",
    "    return self.q.sum(axis=0)\n",
    "  \n",
    "  def _conditional_target(self, k_index):\n",
    "    return self.q[k_index]/self.q[k_index].sum()\n",
    "  \n",
    "  def _marginal_conductivity(self):\n",
    "    return self.q.sum(axis=1)\n",
    "    \n",
    "  def _update_belief(self, p_o_given_s):\n",
    "    joint = p_o_given_s * self.q\n",
    "    return joint / joint.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b54bce-c708-4f0e-9845-ec47a8a148ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "class UserModel:\n",
    "  \n",
    "  def __init__(self, \n",
    "               num_targets, # how many targets are there?\n",
    "               conductivity, # what is my assumption about the user lag\n",
    "               stdev, # what is my noise assumption over target tracking precision?):\n",
    "               bounds, # what is the user's operating range\n",
    "               p_fp=0.05, # chance of false positive trigger\n",
    "               p_fn=0.01, # chance of a missed goal switch\n",
    "              ):\n",
    "    self.num_targets = num_targets\n",
    "    self.k = conductivity\n",
    "    self.stdev = stdev\n",
    "    self.bounds = bounds\n",
    "    self.p_fp = p_fp\n",
    "    self.p_fn = p_fn\n",
    "    \n",
    "  def copy(self):\n",
    "    # no need to copy because the model is stateless\n",
    "    print('Returning self, because we assume UserModel is stateless.')\n",
    "    return self\n",
    "  \n",
    "  def get_probabilities(self, action):\n",
    "    user_action = action['user']\n",
    "    user_now = user_action['x']\n",
    "    user_prev = user_now - user_action['dx']\n",
    "    ui_state = action['ui']['x']\n",
    "    has_triggered = action['trigger_out'].sum() > 0\n",
    "    \n",
    "    # simple user model: \n",
    "    # - expected user x is previous user x lagging ui x with assumed conductivity\n",
    "    # - consider user operating range is bounded -> bound target position\n",
    "    # - assume some Gaussian density around clipped expected user x\n",
    "    expected_user_x = np.outer(1-self.k, user_prev) + np.outer(self.k, ui_state)\n",
    "    expected_user_x = np.clip(expected_user_x, self.bounds[0], self.bounds[1])\n",
    "    p_o_given_s = norm.pdf(user_now, loc=expected_user_x, scale=self.stdev)\n",
    "    \n",
    "    # - user is likely to switch goals when a trigger occured\n",
    "    p_switch = has_triggered*(1-self.p_fp) + (1-has_triggered) * self.p_fn\n",
    "    return {'p_o_given_s': p_o_given_s, 'p_switch': p_switch}\n",
    "  \n",
    "  def sample_action(self, o, conductivity):\n",
    "    user_last = o['user']['x']\n",
    "    ui_state = o['ui']['x']\n",
    "    i = o['user_target']['s']\n",
    "    k = conductivity\n",
    "    # mean output\n",
    "    expected_user_x = (1-k)*user_last + k*ui_state[i]\n",
    "    expected_user_x = np.clip(expected_user_x, self.bounds[0], self.bounds[1])\n",
    "    # sample from selected state's emission probability\n",
    "    user_next = norm.rvs(loc=expected_user_x, scale=self.stdev, size=1, random_state=None)\n",
    "    return {'x': user_next, 'dx': user_next - user_last}\n",
    "\n",
    "# build the model\n",
    "model = UserModel(num_targets=ui.N, \n",
    "              conductivity=user_lag.k,\n",
    "              stdev=user_noise.stdev, \n",
    "              bounds=user_lag.bounds)\n",
    "\n",
    "observer = BayesianObserver(model=model, \n",
    "              q0_target=np.ones(ui.N)/ui.N, \n",
    "              q0_conductivity=1., \n",
    "              rng=rng)\n",
    "\n",
    "qs = [observer.reset()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c612f-b53a-4509-8de5-afbc62ad740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionLoop:\n",
    "  \n",
    "  def __init__(self, \n",
    "               num_targets, \n",
    "               threshold,\n",
    "               rng,\n",
    "               user_conductivity=0.1,\n",
    "               user_bounds=[-200,200],\n",
    "               user_stdev=10.):\n",
    "    self.ui = HarmonicOscillator(N=num_targets, mass=0.1, dt=0.02, energy_start=3e3, energy_max=6e3)\n",
    "    # close the loop with a first-order lag user\n",
    "    self.user_target = TargetGenerator(rng=rng, num_targets=num_targets)\n",
    "    user_lag = FirstOrderLag(conductivity=user_conductivity, bounds=user_bounds)\n",
    "    user_noise = Gaussian(stdev=user_stdev, rng=rng)\n",
    "    self.user = NoisyLag(lag=user_lag, noise=user_noise)\n",
    "    # filter energy for selection trigger\n",
    "    self.trigger_in = FirstOrderLag(conductivity=0.05, s0 = np.ones(num_targets) * self.ui.energy_start)\n",
    "    # trigger by thresholding\n",
    "    self.threshold = threshold * self.ui.energy_start\n",
    "    # Active Inference observer\n",
    "    num_k =11\n",
    "    k = np.linspace(0.0, 0.2, num_k)\n",
    "    q0_target = np.ones(num_targets)/num_targets\n",
    "    q0_k = np.ones(num_k)/num_k\n",
    "    # successive user steps are more correlated than iid Gaussian on the output -> reduce noise from observation noise\n",
    "    model = UserModel(num_targets=num_targets, \n",
    "              conductivity=k, \n",
    "              stdev=user_stdev*0.25, \n",
    "              bounds=user_bounds)\n",
    "    \n",
    "    self.observer = BayesianObserver(model=model, \n",
    "                       q0_target=q0_target, \n",
    "                       q0_conductivity=q0_k, rng=rng)\n",
    "    \n",
    "  def reset(self):\n",
    "    o = {}\n",
    "    o['ui'] = self.ui.reset()\n",
    "    o['user'] = self.user.reset()\n",
    "    o['user_target'] = self.user_target.reset()\n",
    "    o['trigger_in'] = self.trigger_in.reset()['x']\n",
    "    o['trigger_out'] = self.trigger_out(o['trigger_in'])\n",
    "    o['belief'] = self.observer.reset()\n",
    "    self.s = o\n",
    "    return self.s\n",
    "  \n",
    "  def step(self):\n",
    "    a = self.s\n",
    "    # reset UI when event has been triggered\n",
    "    if a['trigger_out'].sum() > 0:\n",
    "      self.ui.reset()\n",
    "      self.trigger_in.reset()\n",
    "\n",
    "    o = {}\n",
    "    o['ui'] = self.ui.step(a['user']['x'])\n",
    "    o['trigger_in'] = self.trigger_in.step(o['ui']['debug']['energy'])['x']\n",
    "    o['trigger_out'] = self.trigger_out(o['trigger_in'])\n",
    "\n",
    "    # resample user goal if their target has been triggered\n",
    "    o['user_target'] = self.user_target.step(a['trigger_out'])\n",
    "    o['user'] = self.user.step(o['ui']['x'][o['user_target']['s']])\n",
    "    # update observer\n",
    "    o['belief'] = self.observer.step(o)\n",
    "    self.s = o\n",
    "    return self.s\n",
    "    \n",
    "  def trigger_out(self, inputs):\n",
    "    return inputs < self.threshold\n",
    "  \n",
    "num_targets = 8\n",
    "threshold = 0.2\n",
    "num_steps = 400\n",
    "\n",
    "loop = InteractionLoop(num_targets=num_targets, threshold=threshold, rng=rng)\n",
    "os = [loop.reset()] + [loop.step() for _ in range(num_steps)]\n",
    "print(os[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop model\n",
    "class LoopModel:\n",
    "  \"\"\" Rollout of User-UI interaction in response to active inference agent actions. \"\"\"\n",
    "  \n",
    "  def __init__(self, loop, prev_obs, user_state):\n",
    "    self.loop = loop\n",
    "    self.s = prev_obs\n",
    "    self.user_state = user_state\n",
    "    \n",
    "    self.ui = loop.ui.copy()\n",
    "    self.trigger_in = loop.trigger_in.copy()\n",
    "    self.trigger_out_fn = loop.trigger_out\n",
    "    self.user_target = loop.user_target.copy()\n",
    "    self.user_target.assign(self.user_state['target']) # init user target\n",
    "    self.user_model = loop.observer.model\n",
    "    self.observer = loop.observer.copy()\n",
    "    \n",
    "    self.s = prev_obs\n",
    "    \n",
    "  def step(self, control_state=None):\n",
    "    # implement the action\n",
    "    if control_state is not None:\n",
    "      self.ui.mass = self.ui.mass * (1+control_state)\n",
    "    \n",
    "    s = self.s\n",
    "    # propagate model through time\n",
    "    # - reset UI when event has been triggered\n",
    "    if s['trigger_out'].sum() > 0:\n",
    "      self.ui.reset()\n",
    "      self.trigger_in.reset()\n",
    "      \n",
    "    o = {}\n",
    "    o['ui'] = self.ui.step(s['user']['x'])\n",
    "    o['trigger_in'] = self.trigger_in.step(o['ui']['debug']['energy'])['x']\n",
    "    o['trigger_out'] = self.trigger_out_fn(o['trigger_in'])\n",
    "    \n",
    "    # resample user goal if their target has been triggered\n",
    "    o['user_target'] = self.user_target.step(s['trigger_out'])\n",
    "    o['user'] = s['user'] # pass last state to user for lag estimation\n",
    "    o['user'] = self.user_model.sample_action(o, self.user_state['conductivity'])\n",
    "\n",
    "    # update belief over user hidden state\n",
    "    o['belief'] = self.observer.step(o)\n",
    "    \n",
    "    self.s = o\n",
    "    return self.s\n",
    "    \n",
    "# simulate some burn in\n",
    "os = [loop.reset()] + [loop.step() for _ in range(50)]\n",
    "    \n",
    "# construct action evaluation\n",
    "\n",
    "# setup\n",
    "num_targets = 8\n",
    "time_horizon = 100 # maximum time to consider\n",
    "delta_mass = 0.5\n",
    "num_rollouts = 16\n",
    "# control states\n",
    "us = np.vstack([\n",
    "        np.eye(num_targets) * 4, # target_value / mass_0 - 1\n",
    "        np.eye(num_targets) * -0.8, \n",
    "        np.zeros((1,num_targets))])\n",
    "\n",
    "num_actions = len(us)\n",
    "print(us.shape)\n",
    "# define pragmatic value\n",
    "p_c = [0.05-1e-4, # triggered nothing\n",
    "       0.95, # triggered target\n",
    "       1e-4] # triggered the wrong\n",
    "log_p_c = np.log(p_c)\n",
    "\n",
    "# generate a set of plans, each doing nothing after the first timestep\n",
    "first_action = np.arange(num_actions)[:,None]\n",
    "remaining_actions = np.ones((num_actions, time_horizon-1)) * (num_actions - 1)\n",
    "plans = np.hstack( [first_action, remaining_actions] ).astype(int)\n",
    "\n",
    "# - test concept with plan of always taking no action\n",
    "nefes = []\n",
    "for plan in plans:\n",
    "  #print(plan)\n",
    "  total_steps = 0\n",
    "  pragmatic = 0\n",
    "  for _ in range(num_rollouts):\n",
    "    # - sample user state from belief distribution\n",
    "    user_state = loop.observer.sample()\n",
    "    # - rollout policy over fixed time horizon or crop if trigger occured\n",
    "    loop_model = LoopModel(loop=loop, prev_obs=os[-1], user_state=user_state)\n",
    "    q_ss = []\n",
    "    for a in plan:\n",
    "      q_ss.append(loop_model.step(us[a]))\n",
    "      if q_ss[-1]['trigger_out'].sum() > 0:\n",
    "        break\n",
    "    \n",
    "    pragmatic += (len(q_ss)-1) * log_p_c[0] # all but one timestep was not triggered\n",
    "    if q_ss[-1]['trigger_out'].sum() < 0.5:\n",
    "      pragmatic += log_p_c[0]\n",
    "    elif q_ss[-1]['trigger_out'][user_state['target']]:\n",
    "      pragmatic += log_p_c[1]\n",
    "    else:\n",
    "      pragmatic += log_p_c[2]\n",
    "      \n",
    "    total_steps += len(q_ss)\n",
    "        \n",
    "  nefes.append(pragmatic/ total_steps)\n",
    "  \n",
    "plt.plot(nefes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99603f-d51c-4db7-939d-e873fb13efd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86af8da-58ad-4eef-95a3-a543e79a1403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbea387-4679-4675-8669-c45e4349c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot belief\n",
    "os_view = q_ss\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3*8, 6))\n",
    "\n",
    "# joint instantaneous belief\n",
    "plt.sca(axes[0])\n",
    "plt.imshow(loop.observer.q, aspect='auto')\n",
    "\n",
    "# belief about targets over time\n",
    "plt.sca(axes[1])\n",
    "qs = [o['belief']['target'] for o in os_view]\n",
    "plt.imshow(np.array(qs).T, aspect='auto')\n",
    "plt.plot([o['user_target']['s'] for o in os_view], 'r', label='true target')\n",
    "plt.legend()\n",
    "\n",
    "# belief about conductivity over time\n",
    "plt.sca(axes[2])\n",
    "qs = [o['belief']['conductivity'] for o in os_view]\n",
    "plt.imshow(np.array(qs).T, aspect='auto')\n",
    "plt.plot([0, len(qs)-1], [user_state['conductivity_index']]*2, 'r', label='simulated lag')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50a5e7-6c21-4337-aa7d-9e4f9dbd566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dynamics\n",
    "os = q_ss\n",
    "\n",
    "def plot_positions(os, ax):\n",
    "  # target positions over time\n",
    "  plt.sca(ax)\n",
    "  plt.title('target positions over time')\n",
    "  xs = np.array([o['ui']['x'] for o in os])\n",
    "  ts = np.array([o['user_target']['s'] for o in os])\n",
    "  plt.plot(xs)\n",
    "  plt.plot(xs[np.arange(ts.shape[0]),ts], 'k-', label='user target')\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('position')  \n",
    "  # user input over time\n",
    "  y = np.array([o['user']['x'] for o in os])\n",
    "  plt.plot(y, 'k--', label='user input')\n",
    "  plt.legend()\n",
    "\n",
    "def plot_velicities(os, ax):\n",
    "  # target velocity over time\n",
    "  plt.sca(ax)\n",
    "  plt.title('target velocities over time')\n",
    "  vs = np.array([o['ui']['v'] for o in os])\n",
    "  plt.plot(vs)\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('velocity')\n",
    "\n",
    "def plot_mass(os, ax):\n",
    "  # target mass over time\n",
    "  plt.sca(ax)\n",
    "  plt.title('mass over time')\n",
    "  ms = np.array([o['ui']['debug']['mass'] for o in os])\n",
    "  plt.plot(ms)\n",
    "  plt.plot(ms[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "  plt.xlabel('timestep  t')\n",
    "  plt.ylabel('mass')\n",
    "\n",
    "def plot_spring(os, ax):\n",
    "  # target spring coefficient\n",
    "  plt.sca(ax)\n",
    "  plt.title('spring coefficient over time')\n",
    "  ss = np.array([o['ui']['debug']['spring'] for o in os])\n",
    "  plt.plot(ss)\n",
    "  plt.plot(ss[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('spring coefficient')\n",
    "\n",
    "def plot_energies(os, ax):\n",
    "  # target energies\n",
    "  plt.sca(ax)\n",
    "  plt.title('energy over time')\n",
    "  es = np.array([o['ui']['debug']['energy'] for o in os])\n",
    "  plt.plot(es)\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('mechanical energy E')\n",
    "  \n",
    "def plot_trigger_input(os, ax):  \n",
    "  # trigger input over time\n",
    "  y = np.array([o['trigger_in'] for o in os])\n",
    "  plt.sca(ax)\n",
    "  plt.plot(y)\n",
    "  plt.plot([0, len(os)], [threshold]*2, 'k--', label='threshold')\n",
    "  plt.legend()\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('trigger input')\n",
    "  plt.title('smoothed energy over time')\n",
    "  \n",
    "def plot_trigger_output(os, ax):\n",
    "  # trigger output over time\n",
    "  y = np.array([o['trigger_out'] for o in os])\n",
    "  plt.sca(axes[7])\n",
    "  plt.plot(y)\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('trigger output')\n",
    "  plt.title('events triggered over time')\n",
    "  \n",
    "def plot_user_target(os, ax):\n",
    "  # user target\n",
    "  plt.sca(ax)\n",
    "  plt.title('user target over time')\n",
    "  ts = np.array([o['user_target']['s_one_hot'] for o in os])\n",
    "  plt.plot(ts, '--')\n",
    "  plt.xlabel('timestep t')\n",
    "  \n",
    "def plot_belief(os, ax, varname='target'):\n",
    "  # plot belief\n",
    "  plt.sca(ax)\n",
    "  plt.title('Observer belief over time')\n",
    "  qs = [o['belief'][varname] for o in os]\n",
    "  plt.imshow(np.array(qs).T, aspect='auto')\n",
    "  plt.plot([o['user_target']['s'] for o in os], 'r')\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('target id')\n",
    "  \n",
    "def plot_max_belief(os, ax, varname='target'):\n",
    "  plt.sca(ax)\n",
    "  plt.title('Observer max. belief over time')\n",
    "  qs = np.array([o['belief'][varname] for o in os])\n",
    "  plt.plot(qs.max(axis=1))\n",
    "\n",
    "num_plots = 3\n",
    "fig, axes = plt.subplots(num_plots, 1, figsize=(12, 4*num_plots))\n",
    "\n",
    "plot_positions(os, axes[0])\n",
    "#plot_velocities(os, axes[1])\n",
    "#plot_mass(os, axes[2])\n",
    "#plot_spring(os, axes[3])\n",
    "plot_energies(os, axes[1])\n",
    "#plot_trigger_input(os, axes[5])\n",
    "#plot_user_target(os, axes[2])\n",
    "#plot_trigger_output(os, axes[7])\n",
    "#plot_belief(os, axes[1])\n",
    "plot_max_belief(os, axes[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e263a-fe37-4156-980f-f9b58cea72b4",
   "metadata": {},
   "source": [
    "## Bayesian Inference of Intent\n",
    "\n",
    "This section runs the Bayesian belief update of an active inference agent on an observed simulation of interaction and visualises the belief over targets.\n",
    "\n",
    "For that we define a likelihood-based generative model of user input. Here, we use a model that is similar to the generative process with some small differences and one free parameter that needs to be inferred from observations of interaction. The user model perceives the oscillator positions exactly, acts to track with some delay represented as a first-order lag with parameter $\\lambda_{model}$ and with motor imprecision represented as Gaussian white noise on the lagging positions.\n",
    "\n",
    "$x_{model} = \\text{lag}(x_{gui}^{t}, x_{usr}^{t-1};\\lambda_{model})+ \\mathcal{N}(0;\\sigma_{model}^2) \\approx x_{usr} = \\text{lag}( \\mathcal{N}(x_{gui};\\sigma_{usr}^2), x_{usr}^{t-1}; \\lambda_{usr} )$\n",
    "\n",
    "While we keep the model very close to the simulated user apart from it not having access to the intended target, \n",
    "itt does not match exactly and the lag parameter $\\lambda_{model}$ is unknown a priori."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c4710-f024-4c9b-944e-776e87f4fd5b",
   "metadata": {},
   "source": [
    "## Acting to increase pragmatic value\n",
    "\n",
    "We show how action can help to gain information about user intent and to increase the probability of observing preferred state by intervening on the mediating mechanism instead of the decision rule itself. This is in contrast to previous work such as BIGNav, which used Bayesin information gain directly for control by triggering events compatible with current belief directly. We argue that the proposed approach is more generalisable as it requires only access to the communication layer as opposed to the controlled software. It can also enable adapting faster to parameters of the user that are consistent across applications, such as touch offsets, by learning from their interaction with multiple applications.\n",
    "\n",
    "In active inference, sequences of actions (plans) are scored by the negative expected free energy, and selected by exponentiating and normalizing, i.e. sampling from the softmax over plans. Plans $\\pi: a_0, a_1, ..., a_{K-1}$ define sequences of actions up to a finite horizon of $K$ timesteps into the future. The expected free energy can be decomposed in various ways and here we chose one that we find most intuitive, involving a _pragmatic_ term and an _information gain_ term. \n",
    "\n",
    "The _pragmatic_ term assesses the probability of arriving in states following $\\pi$ that the agent desires, or of encountering observations that the agent desires. In this context, $Q_\\theta$ is estimated by propagating beliefs through the environment transition dynamics following the sequence of actions defined by $\\pi$, and observations are halucinated by sampling from the emission probability distributions.\n",
    "\n",
    "$\\mathbb{E}_{s \\sim Q_{\\theta}}\\left[\\log p_c(s)\\right] \\quad \\text{or} \\quad \\mathbb{E}_{s \\sim Q_{\\theta}, o \\sim p(o|s)}\\left[\\log p_c(o)\\right]$\n",
    "\n",
    "The _information gain_ term quantifies the belief update due to making observations in future states.\n",
    "\n",
    "$\\mathbb{E}_{s \\sim Q_{\\theta}, o \\sim p(o|s)}\\left[ D_{KL}(\\, Q_{\\theta'}(s|o),  Q_{\\theta}(s) \\,) \\right]$\n",
    "\n",
    "\n",
    "We consider actions to represent interventions on individual masses of the oscillating mechanism associated with different targets. An increase in mass increases kinetic energy and decreases the oscillation frequency, whereas a decrease in mass decreases kinetic energy and increases the oscillation frequency, respectively. A discrete action space is defined over $2N+1$ actions corresponding to no intervention, increasing, or decreasing the mass of $N$ individual targets by a fixed proportion ($\\pm10\\%$).\n",
    "\n",
    "The preferences over states and observations of an adaptive user interface could be informed by a variety of factors including the users' intent, e.g., preferring observations that are compatible with the application behaving as the user intends), the risk associated with different application states, e.g., preferring observations that are incompatible with the application being driven into unsafe states, and a policy to nudge users into preferable application states, e.g., to expose users to new features or to increase their chance of picking more healthy, more economical, or more environmentally friendly options. Because most of these factors assume some domain knowledge of the application to be meaningful, we focus here on the first, i.e. preferring observations that are compatible with user intention.\n",
    "\n",
    "### Option A: preference over trigger events\n",
    "\n",
    "Here, we define the preference distribution over observations as a function of our belief about the user's intended target and observed trigger events. Action selection thereby attempts to drive the dynamic system into a configuration that makes it easier for the user to decrease their intended target's energy, harder for the user to accidentally decrease any other target's energy, and potentially assists with energy reduction directly.\n",
    "\n",
    "One drawback of this approach is that hypothetical trigger events are sparse and we therefore need long rollouts to identify an effect\n",
    "\n",
    "### Option B: preference over energy vectors\n",
    "\n",
    "## Acting to increase information gain\n",
    "\n",
    "In order to resolve ambiguity in user intention to trigger different targets (maximising information gain) it would be useful to desynchronise those targets' movement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845571ec-b4da-49a9-8210-27bc0265c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch action mechanism\n",
    "\n",
    "# generate set of 2*N+1 discrete actions\n",
    "# control states\n",
    "us = np.vstack([\n",
    "        np.eye(num_targets) * 4, # target_value / mass_0 - 1\n",
    "        np.eye(num_targets) * -0.8, \n",
    "        np.zeros((1,num_targets))])\n",
    "\n",
    "# apply control state associated with selected action\n",
    "a = 1\n",
    "mass_pre = np.ones(num_targets)\n",
    "mass_post = mass_pre * (1 + us[a])\n",
    "plt.plot(mass_pre)\n",
    "plt.plot(mass_post)\n",
    "plt.plot(us[a])\n",
    "\n",
    "# evaluate the pragmatic value\n",
    "# - propagate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d37ce-5817-493c-ba9b-43171af47843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete action selection with pragmatic value\n",
    "\n",
    "# 1. do a rollout of the future with sampled initial target state and sampled user model parameter\n",
    "o = os[-1]\n",
    "rollout_target = rng.choice(num_targets, p=o['belief']['target'])\n",
    "rollout_conductivity = rng.choice(loop.observer.model.k, p=o['belief']['conductivity'])\n",
    "print(rollout_target, rollout_conductivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc9490-40ed-40e4-b8f5-7cae41654ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08384fcb-493b-4fc7-b512-bb4f80cebdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af66e49-c83d-410f-9828-05c90982c18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2174c47c-6032-43f2-a6d1-c5a1da4a1e4e",
   "metadata": {},
   "source": [
    "## Selection Trigger (Active Inference)\n",
    "\n",
    "In the simplest setting, we can perform belief updates using the model of the user and of the UI dynamics to reason about the user's target object.\n",
    "\n",
    "In a more advanced setting, we can intervene on the UI to help resolve ambiguity by changing some of the objects' parameters (mass, spring constant, and damping constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f56f3c-85b3-4f4a-927a-6a347dd4034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import harmonic_interaction_01 as hi\n",
    "importlib.reload(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7576c71-5b7b-4e1c-b039-40f051703a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000 * 2\n",
    "\n",
    "agents = hi.init()\n",
    "os = [hi.reset(agents)]\n",
    "for _ in range(num_steps):\n",
    "  os.append(hi.step(agents, os[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd575e9b-dd28-47e7-8f31-95dec1dc4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dynamics\n",
    "fig, axes = plt.subplots(8, 1, figsize=(12, 4*8))\n",
    "\n",
    "# target positions over time\n",
    "plt.sca(axes[0])\n",
    "plt.title('target positions over time')\n",
    "xs = np.array([o['ui']['x'] for o in os])\n",
    "ts = np.array([o['user_target']['s'] for o in os])\n",
    "plt.plot(xs)\n",
    "plt.plot(xs[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('position')\n",
    "\n",
    "# user input over time\n",
    "y = np.array([o['sim_user'] for o in os])\n",
    "plt.plot(y, 'k--', label='user input')\n",
    "plt.legend()\n",
    "\n",
    "# target velocity over time\n",
    "plt.sca(axes[1])\n",
    "plt.title('target velocities over time')\n",
    "vs = np.array([o['ui']['v'] for o in os])\n",
    "plt.plot(vs)\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('velocity')\n",
    "\n",
    "# target mass\n",
    "plt.sca(axes[2])\n",
    "plt.title('mass over time')\n",
    "ms = np.array([o['ui']['debug']['mass'] for o in os])\n",
    "plt.plot(ms)\n",
    "plt.plot(ms[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "plt.xlabel('timestep  t')\n",
    "plt.ylabel('mass')\n",
    "\n",
    "# target spring coefficient\n",
    "plt.sca(axes[3])\n",
    "plt.title('spring coefficient over time')\n",
    "ss = np.array([o['ui']['debug']['spring'] for o in os])\n",
    "plt.plot(ss)\n",
    "plt.plot(ss[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('spring coefficient')\n",
    "\n",
    "# target energies\n",
    "plt.sca(axes[4])\n",
    "plt.title('energy over time')\n",
    "es = np.array([o['ui']['debug']['energy'] for o in os])\n",
    "plt.plot(es)\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('mechanical energy E')\n",
    "\n",
    "# user target\n",
    "plt.sca(axes[5])\n",
    "plt.title('user target over time')\n",
    "ts = np.array([o['user_target']['s_one_hot'] for o in os])\n",
    "plt.plot(ts, '--')\n",
    "plt.xlabel('timestep t')\n",
    "\n",
    "# trigger output over time\n",
    "y = np.array([o['trigger_out'] for o in os])\n",
    "plt.sca(axes[6])\n",
    "plt.plot(y)\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('trigger output')\n",
    "plt.title('events triggered over time')\n",
    "\n",
    "# trigger input over time\n",
    "y = np.array([o['trigger_in'] for o in os])\n",
    "plt.sca(axes[7])\n",
    "plt.plot(y)\n",
    "plt.plot([0, len(os)], [threshold]*2, 'k--', label='threshold')\n",
    "plt.legend()\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('trigger input')\n",
    "plt.title('smoothed energy over time')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23c165-f607-4148-8194-a4972ad4328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = Register(s0=0, bounds=[0.2, 0.8])\n",
    "display(user.reset())\n",
    "display(user.step())\n",
    "display(user.step(2.))\n",
    "display(user.step())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6423e10-6fec-4ee3-9006-7df6f78af83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9820437-5d67-48e9-a562-7f2be6839c26",
   "metadata": {},
   "source": [
    "# Legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6d4bf-b14d-43fd-8f11-b3a2b7ba5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. reason about user intent by observing interaction\n",
    "\n",
    "# a. traditional approach: moving average velocity below threshold, with\n",
    "# initial value, capcity (moving average weight) and threshold finetuned\n",
    "# tie-break on value if threshold is crossed by multiple targets\n",
    "# - fine-tune initial value to maximum peak velocity\n",
    "# - fine-tune conductivity to reduce oscillation in controlled object's score\n",
    "#   near convergence\n",
    "# - fine-tune threshold to separate controlled from uncontrolled objects\n",
    "# - trigger action if a single object's score is below threshold\n",
    "\n",
    "num_objects = 16\n",
    "num_steps = 200\n",
    "fig, ax = plt.subplots(figsize=(8*2, 12))\n",
    "\n",
    "mass = np.ones(num_objects) + np.linspace(0, 1, num_objects)\n",
    "ui = MassSpringDamper(mass=mass, bounds=[-1, 1])\n",
    "user = FirstOrderLag(conductivity=0.1)\n",
    "\n",
    "reasoner = FirstOrderLag(conductivity=0.05, s0=0.1)\n",
    "#reasoner = SimpleMovingAverage(buffer_size=64, s0=np.ones(num_objects)*0.02)\n",
    "threshold = 0.001\n",
    "\n",
    "os_ui = []\n",
    "os_user = []\n",
    "ss_reasoner = []\n",
    "os_reasoner = []\n",
    "\n",
    "user.reset()\n",
    "reasoner.reset()\n",
    "o_ui = ui.reset()\n",
    "\n",
    "for _ in range(num_steps):\n",
    "  # stimulus response - target system at index 0\n",
    "  o_user = user.step(o_ui['x'][-1])\n",
    "  # log stimulus and response\n",
    "  os_ui.append(o_ui['x'])\n",
    "  os_user.append(o_user)\n",
    "  # simulate next stimulus\n",
    "  o_ui = ui.step(o_user)\n",
    "  # reason about ui response to user input\n",
    "  s_reasoner = reasoner.step(np.abs(o_ui['dx']))\n",
    "  o_reasoner = s_reasoner < threshold\n",
    "  ss_reasoner.append(s_reasoner)\n",
    "  os_reasoner.append(o_reasoner)\n",
    "  \"\"\"\n",
    "  if np.sum(o_reasoner > 1e-6):\n",
    "    # object selected\n",
    "    break\n",
    "  \"\"\"\n",
    "  \n",
    "plt.plot(ss_reasoner, '-');\n",
    "plt.plot(np.max(np.array(os_reasoner), axis=1) * np.max(ss_reasoner), 'k-', label='triggered');\n",
    "plt.plot([0, num_steps], [threshold, threshold], 'k--', label='threshold');\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('selection score (lower is better)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578373ad-07cc-4011-8b93-334dde49d632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_inference]",
   "language": "python",
   "name": "conda-env-active_inference-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
