{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1ce48-fac3-4d7c-8985-c7a7fda1131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test script that puts it all together\n",
    "import os\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4369abc-43c4-4264-94ef-af8f5f29d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab7a31-b79b-4d69-98ad-28cb33e930da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# User Interface: Selecting targets by driving a dynamical system into low-energy states\n",
    "\n",
    "To illustrate how active inference can help adapt parameters of complex user interfaces to improve performance, we explore a target selection task with artificially complicated but well understood interaction dynamics. A visual display shows $N$ targets in motion mimicking the harmonic oscillation of masses on springs. All springs are *anchored* at the same height to a horizontal line that is controlled by the user. Each target has a different parametrization corresponding to different oscillation frequencies. A target is selected by reducing its mechanical energy to fall below some threshold $\\tau$ while keeping all other targets' mechanical energies above the threshold. The mechanical energy is defined as the sum of potential energy and kinetic energy, with all energy being kinetic at the zero crossing and all energy being potential at the oscillation extrema. The oscillation amplitude thereby gives the user feedback about the effect of their inputs on progress towards selecting individual targets. Moving the anchor towards or away from a target reduces or increase its potential energy, respectively.\n",
    "\n",
    "The harmonic oscillators act as a common mediating mechanism between various input spaces (e.g., trajectories of a mouse pointer, a visually tracked hand, gaze, or device tilting movements) and the control space (one of $N$ target selection). By decoupling the interaction metaphor from the specific input modality we can leverage users' mental model of the dynamics to make control across multiple modalities more intuitive, provided that parametrisations of the dynamics can be found that work well for each modality and user. Traditionally, finding good parametrisations was done manually or through trial and error user testing in each new context. More recently, computational interaction methods have been proposed, where user models trained via reinforcement learning are used to evaluate individual interface parametrisations in simulation  off-line. Here, we set out to demonstrate how active inference can be used to simultaneously learn the user model and adapt interface parametrisations to optimize task performance on-line, i.e. while a user interacts with the system.\n",
    "\n",
    "## Harmonic Oscillators\n",
    "\n",
    "### Mathematical description\n",
    "\n",
    "We parametrise each harmonic oscillator with a mass $m$ and a spring constant $\\kappa$, which correspond to the oscillation frequency in Eq. X\n",
    "$$f=\\frac{1}{2\\pi}\\sqrt{\\frac{\\kappa}{m}}$$\n",
    "\n",
    "The state is represented by $(x, \\dot x)$ , where $x$ is its distance from the anchor and $\\dot x$ its velocity. The mechanical energy $E$, potential energy $U$, and kinetic energy $K$ are defined as in Eq. X\n",
    "$$\n",
    "E = U + K \n",
    "$$\n",
    "$$ U = \\frac{1}{2}\\kappa \\cdot x^2 $$\n",
    "$$ K = \\frac{1}{2}m \\cdot \\dot x^2 $$\n",
    "\n",
    "The dynamics are described by an ordinary differential equation (ODE) and state updates are performed by taking one Euler step of length $dt$ (see Eq. X)\n",
    "\n",
    "$$ \\ddot x = \\frac{F}{m} = \\frac{-\\kappa \\cdot \\dot x_t}{m} $$\n",
    "$$ \\dot x_t = \\dot x_{t-1} + dt \\cdot \\ddot x_t $$\n",
    "$$ x_t = x_{t-1} + dt \\cdot \\ \\dot x_t$$\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd990fd-cb59-4afe-bfda-f08d99259755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HarmonicOscillator():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 N=1, \n",
    "                 mass=1., \n",
    "                 spring_constant=1., \n",
    "                 damping_coefficient=0., \n",
    "                 dt=0.1, \n",
    "                 energy_start=1., \n",
    "                 energy_max=2):\n",
    "      # config\n",
    "      self.N = N\n",
    "      self.mass_start = mass\n",
    "      self.spring_start = spring_constant\n",
    "      self.damping_start = damping_coefficient\n",
    "      self.dt = dt # Euler step length\n",
    "      self.energy_start = energy_start\n",
    "      self.energy_max = energy_max\n",
    "      # state\n",
    "      self.mass = None\n",
    "      self.spring = None\n",
    "      self.damping = None\n",
    "      self.x = None\n",
    "      self.v = None\n",
    "      self.anchor = 0\n",
    "      \n",
    "    def copy(self):\n",
    "      other = HarmonicOscillator(N=self.N,\n",
    "                                 mass=self.mass_start,\n",
    "                                 spring_constant=self.spring_start,\n",
    "                                 damping_coefficient=self.damping_start,\n",
    "                                 dt=self.dt,\n",
    "                                 energy_start=self.energy_start,\n",
    "                                 energy_max=self.energy_max)\n",
    "      other.mass = self.mass.copy()\n",
    "      other.spring = self.spring.copy()\n",
    "      other.damping = self.damping.copy()\n",
    "      other.x = self.x.copy()\n",
    "      other.v = self.v.copy()\n",
    "      other.anchor = self.anchor\n",
    "      return other               \n",
    "      \n",
    "    def frequency(self):\n",
    "      return 1/(2*np.pi) * np.sqrt(self.spring / self.mass)\n",
    "    \n",
    "    def set_frequency(self, f, atol=1e-2):\n",
    "      # update spring constant to change frequency\n",
    "      # - skip update where current frequency is within tolerance of target\n",
    "      do_update = np.abs(f - self.frequency()) > atol\n",
    "      e_before = self.energy()\n",
    "      ratio = (2*np.pi*f)**2\n",
    "      self.spring = do_update * ratio * self.mass_start + (1-do_update) * self.spring\n",
    "      # update spring constant and mass to reset energy\n",
    "      factor = e_before/self.energy()\n",
    "      self.spring = self.spring * factor * do_update + (1-do_update) * self.spring\n",
    "      self.mass = self.mass * factor * do_update + (1-do_update) * self.mass\n",
    "      \n",
    "    def set_energy(self, energy):\n",
    "      # update position and velocity to change energy\n",
    "      u = self.potential_energy()\n",
    "      k = self.kinetic_energy()\n",
    "      factor = energy / (u+k)\n",
    "      dx = self.x - self.anchor\n",
    "      self.x = np.sqrt(2 * u * factor / self.spring) * np.sign(dx) + self.anchor\n",
    "      self.v = np.sqrt(2 * k * factor / self.mass) * np.sign(self.v)\n",
    "    \n",
    "    def potential_energy(self, x=None, spring=None):\n",
    "      x = self.x if x is None else x\n",
    "      dx = x - self.anchor\n",
    "      spring = self.spring if spring is None else spring\n",
    "      return 0.5 * spring * dx**2\n",
    "    \n",
    "    def kinetic_energy(self, v=None, mass=None):\n",
    "      v = self.v if v is None else v\n",
    "      mass = self.mass if mass is None else mass\n",
    "      return 0.5 * mass * v**2\n",
    "    \n",
    "    def energy(self, x=None, v=None, spring=None, mass=None):\n",
    "      return self.potential_energy(x, spring) + self.kinetic_energy(v, mass)\n",
    "    \n",
    "    def ddot_x(self, dx, v=None, spring=None, damping=None, mass=None):\n",
    "      v = self.v if v is None else v\n",
    "      spring = self.spring if spring is None else spring\n",
    "      damping = self.damping if damping is None else damping\n",
    "      mass = self.mass if mass is None else mass\n",
    "      \n",
    "      f_spring = -spring * dx # reduced spring should reduce spring force\n",
    "      f_friction = -damping * v\n",
    "      f_total = f_spring + f_friction\n",
    "      a = f_total / mass # reduced mass should increase acceleration\n",
    "      return a\n",
    "    \n",
    "    def reset(self):\n",
    "      # self.anchor = self.anchor_start\n",
    "      self.mass = self.mass_start * np.ones(self.N)\n",
    "      self.spring = self.spring_start * np.ones(self.N)\n",
    "      self.damping = self.damping_start * np.ones(self.N)\n",
    "      \n",
    "      # initialise all targets with equal energy and different phase\n",
    "      phase = np.linspace(0, 2*np.pi, self.N+1)[:-1]\n",
    "      e = self.energy_start # total mechanical energy\n",
    "      max_x = np.sqrt(2*e/self.spring) # amplitude along x\n",
    "      self.x = max_x * np.sin(phase) + self.anchor\n",
    "      # note: maximum avoids numerical instability near zero in sqrt\n",
    "      k = np.maximum(0, e - self.potential_energy())\n",
    "      self.v = np.sqrt(2*k/self.mass) * np.sign(np.cos(phase))\n",
    "      return {'x': self.x, 'v': self.v, 'energy': self.energy(),\n",
    "              'debug': {'mass': self.mass, 'spring': self.spring}\n",
    "              }\n",
    "    \n",
    "    def step(self, action=0):\n",
    "      # make hypothetical step with original parameters\n",
    "      self.anchor = action\n",
    "      dx = self.x - self.anchor\n",
    "      a = self.ddot_x(dx)\n",
    "      self.v = self.v + self.dt * a\n",
    "      self.x = self.x + self.dt * self.v\n",
    "      \n",
    "      # boundary condition: limit energy\n",
    "      e = self.energy()\n",
    "      self.set_energy(np.minimum(e, self.energy_max))\n",
    "      \n",
    "      return {'x': self.x, 'v': self.v, 'energy': self.energy(), \n",
    "              'debug': {'mass': self.mass, 'spring': self.spring}\n",
    "             }\n",
    "    \n",
    "    def plot_phase_space(self, axis=None):\n",
    "      if axis is None:\n",
    "        _, axis = plt.subplots()\n",
    "      num_steps = int(np.max(1/(self.frequency() * self.dt))) + 2\n",
    "      outputs = ['x', 'v']\n",
    "      if self.x is None:\n",
    "        self.reset()\n",
    "      \n",
    "      states = {o: [] for o in outputs}\n",
    "      for _ in range(num_steps):\n",
    "        state = self.step()\n",
    "        for o in outputs:\n",
    "          states[o].append(state[o])\n",
    "      \n",
    "      plt.sca(axis)\n",
    "      plt.plot(np.array(states['x']), np.array(states['v']), '-')\n",
    "      plt.title('Phase space');\n",
    "      plt.xlabel('$x$')\n",
    "      plt.ylabel(\"$\\dot x$\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64758230-0e59-4d52-959c-d7b2db340c2b",
   "metadata": {},
   "source": [
    "### Simulations\n",
    "\n",
    "#### Single target with instantaneous intervention on frequency and energy\n",
    "\n",
    "Here we simulate the dynamics of one harmonic oscillator over time with an instantaneous intervention on its frequency and energy at time $t=1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994670f-4937-4539-a9c0-4e8a70469b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate uncontrolled oscillation\n",
    "num_steps = 2_000\n",
    "agent = HarmonicOscillator(N=1, dt=0.01, energy_start=3e3, energy_max=6e3)\n",
    "agent.reset()\n",
    "#agent.plot_phase_space()\n",
    "\n",
    "os = [agent.reset()]\n",
    "for i in range(num_steps):\n",
    "  if i == 1_000:\n",
    "    f = agent.frequency()\n",
    "    e = agent.energy()\n",
    "    \n",
    "    #agent.set_frequency(f*2.)\n",
    "    agent.set_energy(e*0.9)\n",
    "    \n",
    "  os.append(agent.step())\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(2*6, 12))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.title('distance from anchor over time')\n",
    "xs = [o['x'] for o in os]\n",
    "plt.plot(xs)\n",
    "plt.ylabel('distance from anchor x')\n",
    "plt.xlabel('timestep t')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.title('energy over time')\n",
    "es = [o['energy'] for o in os]\n",
    "plt.plot(es)\n",
    "plt.ylabel('energy E = U + K')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylim([0, np.max(es)]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83de81-22bb-400c-a0ac-bd9b64694b15",
   "metadata": {},
   "source": [
    "#### Multiple targets with different masses and spring constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbb2bb-f8b0-4c46-84f6-8672cbcd2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate dynamics of oscillators with different parameters and different energy\n",
    "num_objects = 5\n",
    "mass = np.hstack([ 1 * np.ones((num_objects)), 3 * np.ones(num_objects)]).reshape(-1)\n",
    "spring = np.hstack([ 3 * np.ones((num_objects)), 1 * np.ones(num_objects)]).reshape(-1)\n",
    "agent = HarmonicOscillator(N=2*num_objects, mass=mass, spring_constant=spring)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(2*6, 6))\n",
    "agent.reset()\n",
    "agent.plot_phase_space(axes[0])\n",
    "\n",
    "xs = [agent.reset()['x']]\n",
    "for _ in range(100):\n",
    "  xs.append(agent.step()['x'])\n",
    "  \n",
    "plt.sca(axes[-1])\n",
    "plt.plot(xs);\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31085e-a4a7-463e-8773-0bec7373f3bd",
   "metadata": {},
   "source": [
    "# Optimal Behaviour and User Modelling\n",
    "\n",
    "Optimal user behaviour reduces a target's energy most rapidly. This involves exactly tracking the target's position, instantly absorbing all potential energy as it is converted from kinetic energy. In practice real users have limited precision and act with delays, both present in their visual perception, cognitive process, and motor execution. To capture delays and limited precision, we model user input as a first-order lag with Gaussian noise.\n",
    "\n",
    "## Simulated User\n",
    "\n",
    "### First Order Lag - Implementation and Simulation with a Periodic Step Function\n",
    "\n",
    "We account for perceptual, cognitive and motor delays by modelling the user with a first-order lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f639116-c005-43f6-9797-d7b2ccb80a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Wrap behavior in an agent class.\n",
    "class FirstOrderLag:\n",
    "  \"\"\"\"\n",
    "  First order lag (vectorized).\n",
    "  \n",
    "  Args:\n",
    "      conductivity (np.array): moving average weight of new input, in [0,1].\n",
    "      s0 (np.array): initial state after reset. \n",
    "      bounds (np.array): minimum and maximum state values\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, conductivity=0.5, s0=0, bounds=None):\n",
    "    # config\n",
    "    self.k = conductivity\n",
    "    self.s0 = s0\n",
    "    self.bounds = bounds\n",
    "    # state\n",
    "    self.s = None\n",
    "    \n",
    "  def copy(self):\n",
    "    other = FirstOrderLag(conductivity=self.k,\n",
    "                          s0=self.s0,\n",
    "                          bounds=self.bounds)\n",
    "    other.s = self.s.copy()\n",
    "    return other\n",
    "    \n",
    "  def reset(self):\n",
    "    self.s = np.copy(self.s0)\n",
    "    self.s = self._clip(self.s)\n",
    "    return {'x': self.s, 'dx': np.zeros_like(self.s)}\n",
    "  \n",
    "  def step(self, u):\n",
    "    s = (1-self.k) * self.s + self.k * u\n",
    "    s = self._clip(s)\n",
    "    ds = s - self.s\n",
    "    self.s = s\n",
    "    return {'x': self.s, 'dx': ds}\n",
    "  \n",
    "  def _clip(self, s):\n",
    "    if self.bounds is None:\n",
    "      return s\n",
    "    \n",
    "    return np.clip(s, self.bounds[0], self.bounds[1])\n",
    "  \n",
    "# control signal u\n",
    "num_repetitions = 3\n",
    "num_steps_per_phase = 10\n",
    "u = np.hstack([np.zeros((num_repetitions, num_steps_per_phase)), np.ones((num_repetitions, num_steps_per_phase))]).reshape(-1)\n",
    "  \n",
    "lag = FirstOrderLag(conductivity=0.2)\n",
    "lag.reset()\n",
    "y = [lag.step(u[t]) for t in range(u.shape[0])]\n",
    "plt.plot(u, label='target')\n",
    "plt.plot([y['x'] for y in y], label='lag')\n",
    "plt.plot([y['dx'] for y in y], label='d lag')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc15de-40fe-46b5-98a8-c637f29b838c",
   "metadata": {},
   "source": [
    "### Gaussian Noise - Implementation and Simulation with a Periodic Step Function\n",
    "\n",
    "We account for users' perceptual and motor precision with additive Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021a3dd-05d3-439a-b9b8-35cda1f7d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "  \"\"\" Gaussian agent. Adds Gaussian noise to its input. \"\"\"\n",
    "  def __init__(self, rng, stdev=1., a0=0, mode='additive'):\n",
    "    # config\n",
    "    self.rng = rng\n",
    "    self.stdev = stdev\n",
    "    self.a0 = a0 # assumed starting input\n",
    "    self.mode = mode # {'additive', 'scaled'}\n",
    "    self.sample = self._sample_additive\n",
    "    if self.mode == 'multiply':\n",
    "      self.sample = self._sample_multiplicative\n",
    "    \n",
    "  def reset(self):\n",
    "    return self.sample(self.a0)\n",
    "  \n",
    "  def step(self, a):\n",
    "    return self.sample(a)\n",
    "  \n",
    "  def _sample_additive(self, a):\n",
    "    return a + self.rng.normal(size=np.asarray(a).shape) * self.stdev\n",
    "  \n",
    "  def _sample_multiplicative(self, a):\n",
    "    return a * self.rng.normal(size=np.asarray(a).shape) * self.stdev\n",
    "\n",
    "  \n",
    "gaussian = Gaussian(rng=rng, stdev=0.2, a0=0, mode='additive')\n",
    "xs = [gaussian.step(u[t]) for t in range(u.shape[0])]\n",
    "plt.plot(xs, label='noisy user');\n",
    "plt.plot(u, label='target');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd3cd22-4162-4e98-a83e-6cef4a0a0d7e",
   "metadata": {},
   "source": [
    "### Noisy Lag - Combining First-order Lag with Gaussian Noise\n",
    "\n",
    "The simulated user is represented by a composition of first-order lag and Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b502ab3-122e-4570-be2a-02ef7c10b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLag:\n",
    "  \"\"\" \n",
    "  First-order lag on noisy observations. \n",
    "  Used as a model for user input. \n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, noise, lag):\n",
    "    # config\n",
    "    self.noise = noise\n",
    "    self.lag = lag\n",
    "    \n",
    "  def reset(self):\n",
    "    # treat lag value as noisy observation of the state\n",
    "    x = self.lag.reset()['x']\n",
    "    x_noisy = self.noise.step(x)\n",
    "    self.lag.s = self.lag._clip(x_noisy)\n",
    "    return {'x': x_noisy, 'dx': 0}\n",
    "    \n",
    "  def step(self, action):\n",
    "    # noisy percept of true position\n",
    "    x_noisy = self.noise.step(action)\n",
    "    # tracking perceived position\n",
    "    return self.lag.step(x_noisy)\n",
    "    \n",
    "lag = FirstOrderLag(conductivity=0.2)\n",
    "noise = Gaussian(stdev=0.2, rng=rng)\n",
    "user = NoisyLag(lag=lag, noise=noise)\n",
    "\n",
    "user.reset()\n",
    "y = [user.step(u[t]) for t in range(u.shape[0])]\n",
    "plt.plot(u, label='target')\n",
    "plt.plot([y['x'] for y in y], label='user')\n",
    "plt.plot([y['dx'] for y in y], label='$\\delta t$ of user')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be2889-2eed-42d0-bf4e-1392b76a4b3e",
   "metadata": {},
   "source": [
    "## Closed-loop Feedback Control\n",
    "\n",
    "### Single object to control\n",
    "\n",
    "Let's start building a closed-loop interactive system where the _User_, the _App_ and their _Interaction_ are modeled as hierarchies of agents. This may seem somewhat over the top for now, but will become increasingly valuable as we build out the logic for both the agent and the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14920730-c958-477a-9d6a-915eb7bffbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. simulate MassSpringDamper controlled by FirstOrderLag\n",
    "class AppA:\n",
    "  # thin wrapper around the app; this will contain more complex logic below\n",
    "  def __init__(self, num_targets=1, dt=0.1):\n",
    "    self.targets = HarmonicOscillator(N=num_targets, dt=dt, energy_start=3e3, energy_max=6e3)\n",
    "    \n",
    "  def reset(self):\n",
    "    return {'targets': self.targets.reset()}\n",
    "  \n",
    "  def step(self, action={'x': 0}):\n",
    "    return {'targets': self.targets.step(action['x'])}\n",
    "  \n",
    "  \n",
    "class UserA:\n",
    "  # noisy lag of a specified target; we'll expand on this with a random\n",
    "  # target generator below.\n",
    "  def __init__(self, target=0, conductivity=0.2, noise_scale=1.0, rng=rng):\n",
    "    self.target = target\n",
    "    \n",
    "    self.lag = FirstOrderLag(conductivity=conductivity, s0 = np.zeros(1))\n",
    "    self.noise = Gaussian(stdev=noise_scale, rng=rng)\n",
    "    self.motor = NoisyLag(lag=self.lag, noise=self.noise)\n",
    "    \n",
    "  def reset(self):\n",
    "    return self.motor.reset()\n",
    "  \n",
    "  def step(self, observation):\n",
    "    return self.motor.step(observation['targets']['x'][self.target])\n",
    "  \n",
    "  \n",
    "class Interaction:\n",
    "  # interface between the app and the user, represented as a composite agent\n",
    "  def __init__(self, app, user):\n",
    "    self.app = app\n",
    "    self.user = user\n",
    "    \n",
    "  def reset(self):\n",
    "    return {'app': self.app.reset(),\n",
    "         'user': self.user.reset()}\n",
    "  \n",
    "  def step(self, last_state):\n",
    "    o = {}\n",
    "    o['app'] = self.app.step(last_state['user'])\n",
    "    o['user'] = self.user.step(o['app'])\n",
    "    return o\n",
    "\n",
    "\n",
    "num_steps = 5_00\n",
    "\n",
    "app = AppA(dt=0.05)\n",
    "user = UserA(conductivity=0.02, noise_scale=20.0)\n",
    "system = Interaction(user=user, app=app)\n",
    "\n",
    "# generate an uncontrolled sequence as baseline\n",
    "app.reset()\n",
    "xs_uncontrolled = [app.reset()['targets']['x']] + [app.step()['targets']['x'] for _ in range(num_steps)]\n",
    "\n",
    "# simulate closed-loop\n",
    "os = [system.reset()]\n",
    "for i in range(num_steps):\n",
    "  os.append(system.step(os[-1]))\n",
    "\n",
    "plt.plot(np.array(xs_uncontrolled)[:,user.target], 'r--', linewidth=1., label='uncontrolled system')\n",
    "plt.plot([o['app']['targets']['x'] for o in os], label='controlled system')\n",
    "plt.plot([o['user']['x'] for o in os], label='control signal')\n",
    "plt.title('position over time')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61ed4a-9df2-4ce6-9d29-a58106443d25",
   "metadata": {},
   "source": [
    "### Selective Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee36ae-abc9-4899-a631-95c5671bb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. simulate a set of MassSpringDampers with different mass and selective control with FirstOrderLag\n",
    "num_steps = 5_00\n",
    "num_targets = 16\n",
    "user_target = 2\n",
    "\n",
    "app = AppA(num_targets=num_targets, dt=0.05)\n",
    "user = UserA(target=user_target, conductivity=0.02, noise_scale=20.0)\n",
    "system = Interaction(user=user, app=app)\n",
    "# generate an uncontrolled sequence as baseline\n",
    "app.reset()\n",
    "xs_uncontrolled = [app.reset()['targets']['x']] + [app.step()['targets']['x'] for _ in range(num_steps)]\n",
    "# simulate closed-loop\n",
    "os = [system.reset()]\n",
    "for i in range(num_steps):\n",
    "  os.append(system.step(os[-1]))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(2*6, 12))\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.title('Position over time')\n",
    "xs = [o['app']['targets']['x'] for o in os]\n",
    "\n",
    "#plt.plot(np.array(xs_uncontrolled)[:,user_target], 'r--', linewidth=1., label='uncontrolled system')\n",
    "plt.plot(np.array(xs)[:,user_target], 'r', label='controlled system')\n",
    "plt.plot([o['user']['x'] for o in os], label='control signal')\n",
    "plt.plot(xs, 'gray', alpha=0.5)\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('absolute position')\n",
    "plt.legend()\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.title('Energy over time')\n",
    "es = [o['app']['targets']['energy'] for o in os]\n",
    "plt.plot(es, 'gray', alpha=0.5)\n",
    "plt.plot(np.array(es)[:,user_target], 'r')\n",
    "plt.ylabel('mechanical energy E')\n",
    "plt.xlabel('timestep t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745135c-7377-4862-8e3f-7df8b02c96f8",
   "metadata": {},
   "source": [
    "### Selection Trigger\n",
    "\n",
    "This section develops the mechanism within the app that triggers events associated with oscillating targets. Conceptually, an event should be triggered once an oscillating target's energy has been reduced to fall below a threshold. Practically, we need to consider false positive events triggered by transient low-energy objects. To address this, we use a filtered version of the energy as input to the treshold, where the filter is a first-order lag with conductivity that is than the assumed model user.\n",
    "\n",
    "As the number of targets increases\n",
    "- the threshold needs lowered\n",
    "- the EMA conductivity needs to be reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b4e10-1833-4d9f-8120-3e1fbf5ebc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class App:\n",
    "  # agent representing the app, a composition of other agents\n",
    "  def __init__(self, \n",
    "               num_targets=8, \n",
    "               dt=0.1,\n",
    "               energy_start=3e3, \n",
    "               trigger_conductivity=0.1,\n",
    "               trigger_threshold=0.2):\n",
    "    # config\n",
    "    self.num_targets = num_targets\n",
    "    self.energy_start = energy_start\n",
    "    # trigger event once filtered energy falls below a threshold\n",
    "    threshold = trigger_threshold * energy_start\n",
    "    self.threshold = threshold\n",
    "    self.targets = HarmonicOscillator(N=num_targets, dt=dt, energy_start=3e3, energy_max=6e3)\n",
    "    self.trigger_in = FirstOrderLag(conductivity=trigger_conductivity, \n",
    "                                    s0=np.ones(num_targets) * energy_start)\n",
    "    self.events = lambda x: x < threshold\n",
    "    \n",
    "  def reset(self):\n",
    "    targets = self.targets.reset()\n",
    "    trigger_in = self.trigger_in.reset()\n",
    "    events = self.events(trigger_in['x'])\n",
    "    return {'targets': targets, 'events': events, 'latent': {'trigger_in': trigger_in}}\n",
    "  \n",
    "  def step(self, action):\n",
    "    targets = self.targets.step(action['x'])\n",
    "    trigger_in = self.trigger_in.step(targets['energy'])\n",
    "    events = self.events(trigger_in['x'])\n",
    "    # reset if necessary\n",
    "    if events.sum() > 1e-6:\n",
    "      targets = self.targets.reset()\n",
    "      trigger_in = self.trigger_in.reset()\n",
    "      \n",
    "    self.s = {'targets': targets, 'events': events, 'latent': {'trigger_in': trigger_in}}\n",
    "    return self.s\n",
    "\n",
    "num_steps = 5_00\n",
    "user_target = 0\n",
    "  \n",
    "app = App(num_targets=8, dt=0.05)\n",
    "user = UserA(target=user_target, conductivity=0.02, noise_scale=20.0)\n",
    "system = Interaction(user=user, app=app)\n",
    "\n",
    "# simulate closed-loop\n",
    "os = [system.reset()]\n",
    "for i in range(num_steps):\n",
    "  os.append(system.step(os[-1]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "es_ema = [o['app']['latent']['trigger_in']['x'] for o in os]\n",
    "plt.plot(np.array(es_ema)[:,user_target], label='controlled system')\n",
    "plt.plot([0, len(os)], [app.threshold]*2, 'r--', linewidth=1., label='threshold')\n",
    "plt.plot(es_ema, 'gray', alpha=0.5, linewidth=1.)\n",
    "plt.plot(np.array([o['app']['events'].max() for o in os])*2*app.energy_start, 'k', linewidth=1, label='events');\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('smoothed energy EMA( E )')\n",
    "plt.title('smoothed energy over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4be2f-0a25-4ded-ab86-b9ae1ab74b7d",
   "metadata": {},
   "source": [
    "### Sequential Target Generation\n",
    "\n",
    "A user model for the full interaction requires a model of choosing the next target once the previous target has been selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009cb7b0-6d77-470f-bb01-e0e439eb8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User target generator\n",
    "class TargetGenerator():\n",
    "  \n",
    "  def __init__(self, num_targets, rng):\n",
    "    # config\n",
    "    self.num_targets = num_targets\n",
    "    self.rng = rng\n",
    "    # state\n",
    "    self.s = None\n",
    "    self.s_one_hot = None\n",
    "    \n",
    "  def copy(self):\n",
    "    other = TargetGenerator(num_targets=self.num_targets,\n",
    "                           rng=self.rng)\n",
    "    other.s = self.s\n",
    "    other.s_one_hot = self.s_one_hot.copy()\n",
    "    return other\n",
    "    \n",
    "  def reset(self):\n",
    "    self.assign(rng.choice(self.num_targets))\n",
    "    return self.observation()\n",
    "  \n",
    "  def assign(self, target):\n",
    "    self.s = target\n",
    "    self.s_one_hot = np.eye(self.num_targets)[self.s]\n",
    "  \n",
    "  def step(self, trigger_out):\n",
    "    # reset if true positive\n",
    "    if trigger_out.sum() > 0 and trigger_out[self.s]:\n",
    "      return self.reset()\n",
    "    \n",
    "    return self.observation()\n",
    "  \n",
    "  def observation(self):\n",
    "    return {'s': self.s, 's_one_hot': self.s_one_hot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511040d-da02-4b2d-9191-15500ae81949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "  # noisy lag of a specified target\n",
    "  def __init__(self, num_targets, conductivity=0.2, bounds=None):\n",
    "    self.target = TargetGenerator(rng=rng, num_targets=num_targets)\n",
    "    self.lag = FirstOrderLag(conductivity=conductivity, s0 = np.zeros(1), bounds=bounds)\n",
    "    self.noise = Gaussian(stdev=10., rng=rng)\n",
    "    self.motor = NoisyLag(lag=self.lag, noise=self.noise)\n",
    "    \n",
    "  def reset(self):\n",
    "    target = self.target.reset()\n",
    "    output = self.motor.reset()\n",
    "    output['latent'] = {'target': target}\n",
    "    return output\n",
    "  \n",
    "  def step(self, app):\n",
    "    target = self.target.step(app['events'])\n",
    "    output = self.motor.step(app['targets']['x'][target['s']])\n",
    "    output['latent'] = {'target': target}\n",
    "    return output\n",
    "\n",
    "# setup\n",
    "num_steps = 5_00\n",
    "app = App(num_targets=8, \n",
    "          dt=0.05,\n",
    "          trigger_threshold=0.2, \n",
    "          trigger_conductivity=0.06)\n",
    "user = User(num_targets=app.num_targets)\n",
    "system = Interaction(user=user, app=app)\n",
    "\n",
    "# simulion\n",
    "os = [system.reset()]\n",
    "for i in range(num_steps):\n",
    "  os.append(system.step(os[-1]))\n",
    "\n",
    "# visualisation\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "targets = [o['app']['latent']['trigger_in']['x'][o['user']['latent']['target']['s']] for o in os]\n",
    "plt.plot(targets, label='controlled system')\n",
    "plt.plot([0, len(os)], [app.threshold]*2, 'r--', linewidth=1., label='threshold')\n",
    "es_ema = [o['app']['latent']['trigger_in']['x'] for o in os]\n",
    "plt.plot(es_ema, 'gray', alpha=0.5, linewidth=1.)\n",
    "plt.plot(np.array([o['app']['events'].max() for o in os])*2*app.energy_start, 'k', linewidth=1, label='events');\n",
    "plt.legend()\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('smoothed energy EMA(E)')\n",
    "plt.title('smoothed energy over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d60bb8-656d-486e-8895-f0b8ebc5beb5",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now we have a complete system of a user generating sequences of intended targets and enacting movements consistent with controlling them, and an application that animates the movement of targets and triggers events associated with targets that appear to be controlled by the user.\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "How well does this system perform?\n",
    "\n",
    "To quantitatively evaluate the performance of this system, we measure _accuracy_ and _latency_ of the system under a nominal user, and _generalisation_ to varied user behavior.\n",
    "\n",
    "- expected number of steps to trigger the intended target (latency)\n",
    "- precision (true positives over true positives + false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053233e-1305-4ba9-a5c5-2d00a2105be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "  def __init__(self, system):\n",
    "    self.system = system\n",
    "    # state\n",
    "    self.num_steps = None # total number of environment steps\n",
    "    self.num_tp = None # total number of true positive triggers\n",
    "    self.num_fp = None # total number of false positive triggers\n",
    "    \n",
    "  def reset(self):\n",
    "    self.num_steps = 0\n",
    "    self.num_tp = 0\n",
    "    self.num_fp = 0\n",
    "    system = self.system.reset()\n",
    "    return {'N': self.num_steps, \n",
    "            'TP': self.num_tp,\n",
    "            'FP': self.num_fp,\n",
    "            'system': system}\n",
    "  \n",
    "  def step(self, last_state):\n",
    "    system = self.system.step(last_state['system'])\n",
    "    self.num_steps += 1\n",
    "    if system['app']['events'].sum() > 1e-6:\n",
    "      if system['app']['events'][last_state['system']['user']['latent']['target']['s']] > 1e-6:\n",
    "        self.num_tp += 1\n",
    "      else:\n",
    "        self.num_fp += 1\n",
    "        \n",
    "    return {'N': self.num_steps, \n",
    "            'TP': self.num_tp,\n",
    "            'FP': self.num_fp,\n",
    "            'system': system}\n",
    "  \n",
    "# setup  \n",
    "# double targets, halve conductivity and threshold\n",
    "app = App(num_targets=32, \n",
    "          trigger_conductivity=0.07,\n",
    "          trigger_threshold=0.08)\n",
    "user = User(num_targets=app.num_targets)\n",
    "system = Interaction(user=user, app=app)\n",
    "experiment = Evaluation(system)\n",
    "\n",
    "# simulation\n",
    "os = [experiment.reset()]\n",
    "for _ in range(100_000):\n",
    "  os.append(experiment.step(os[-1]))\n",
    "  \n",
    "# visualisation\n",
    "fig, ax = plt.subplots(1, 2, figsize=(2*8, 6))\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.title('Frequency of true positive events.')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('Latency: no. of steps per TP')\n",
    "plt.plot([o['N']/np.maximum(1, o['TP']) for o in os[1:]])\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.title('Precision over time.')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('Precision: TP / (TP + FP)')\n",
    "plt.plot([0, len(os)], [0.95]*2, '--', linewidth=1., label='95%')\n",
    "plt.plot([o['TP']/np.maximum(o['TP']+o['FP'], 1) for o in os[1:]])\n",
    "#plt.plot([o['TP'] for o in os[1:]], label='TP')\n",
    "#plt.plot([o['FP'] for o in os[1:]], label='FP')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74249f55-a1d5-40fa-95d6-c386e00b0d7f",
   "metadata": {},
   "source": [
    "### Useful Parameters\n",
    "\n",
    "| Targets | Lag | Thresh |\n",
    "| --: |  --: |  --: |\n",
    "|   8 |  0.1 |  0.2 |\n",
    "|  16 | 0.09 | 0.12 | \n",
    "|  32 | 0.07 | 0.07 |\n",
    "|  64 | 0.04 | 0.04 |\n",
    "| 128 | 0.01 | 0.02 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e263a-fe37-4156-980f-f9b58cea72b4",
   "metadata": {},
   "source": [
    "# Active Inference\n",
    "\n",
    "## Bayesian Inference of Intent\n",
    "\n",
    "This section runs the Bayesian belief update of an active inference agent on an observed simulation of interaction and visualises the belief over targets.\n",
    "\n",
    "For that we define a likelihood-based generative model of user input. Here, we use a model that is similar to the generative process (Simulated User) with some small differences and one free parameter that needs to be inferred from observations of interaction. The user model perceives the oscillator positions exactly, acts to track with some delay represented as a first-order lag with parameter $\\lambda_{model}$ and with motor imprecision represented as Gaussian white noise on the lagging positions.\n",
    "\n",
    "$x_{model} = \\text{lag}(x_{gui}^{t}, x_{usr}^{t-1};\\lambda_{model})+ \\mathcal{N}(0;\\sigma_{model}^2) \\approx x_{usr} = \\text{lag}( \\mathcal{N}(x_{gui};\\sigma_{usr}^2), x_{usr}^{t-1}; \\lambda_{usr} )$\n",
    "\n",
    "While we keep the model very close to the simulated user apart from it not having access to the intended target, \n",
    "itt does not match exactly and the lag parameter $\\lambda_{model}$ is unknown a priori.\n",
    "\n",
    "### User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b54bce-c708-4f0e-9845-ec47a8a148ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "class UserModel:\n",
    "  \n",
    "  def __init__(self, \n",
    "               num_targets, # how many targets are there?\n",
    "               conductivity, # what is my assumption about the user lag\n",
    "               stdev, # what is my noise assumption over target tracking precision?):\n",
    "               bounds, # what is the user's operating range\n",
    "               p_fp=0.05, # chance of false positive event\n",
    "               p_fn=0.01, # chance of false negative, i.e. user switched target without an event firing\n",
    "              ):\n",
    "    # config\n",
    "    self.num_targets = num_targets\n",
    "    self.k = conductivity\n",
    "    self.stdev = stdev\n",
    "    self.bounds = bounds\n",
    "    self.p_fp = p_fp\n",
    "    self.p_fn = p_fn\n",
    "    \n",
    "  def copy(self):\n",
    "    # no need to copy because the model is stateless\n",
    "    print('Returning self, because we assume UserModel is stateless.')\n",
    "    return self\n",
    "  \n",
    "  def get_probabilities(self, action):\n",
    "    user_action = action['user']\n",
    "    user_now = user_action['x']\n",
    "    user_prev = user_now - user_action['dx']\n",
    "    ui_state = action['app']['targets']['x']\n",
    "    has_triggered = action['app']['events'].sum() > 0\n",
    "    \n",
    "    # simple user model: \n",
    "    # - expected user_x is previous user_x lagging ui with assumed conductivity\n",
    "    # - consider user operating range is bounded -> bound target position\n",
    "    # - assume some Gaussian density around clipped expected user_x\n",
    "    expected_user_x = np.outer(1-self.k, user_prev) + np.outer(self.k, ui_state)\n",
    "    if self.bounds is not None:\n",
    "      expected_user_x = np.clip(expected_user_x, self.bounds[0], self.bounds[1])\n",
    "    p_o_given_s = norm.pdf(user_now, loc=expected_user_x, scale=self.stdev)\n",
    "    \n",
    "    # - user is likely to switch goals when an event occured\n",
    "    p_switch = has_triggered*(1-self.p_fp) + (1-has_triggered) * self.p_fn\n",
    "    return {'p_o_given_s': p_o_given_s, 'p_switch': p_switch}\n",
    "  \n",
    "  def sample_action(self, o, conductivity):\n",
    "    user_last = o['user']['x']\n",
    "    ui_state = o['app']['targets']['x']\n",
    "    i = o['user']['target']['s']\n",
    "    k = conductivity\n",
    "    # mean output\n",
    "    expected_user_x = (1-k)*user_last + k*ui_state[i]\n",
    "    expected_user_x = np.clip(expected_user_x, self.bounds[0], self.bounds[1])\n",
    "    # sample from selected state's emission probability\n",
    "    user_next = norm.rvs(loc=expected_user_x, scale=self.stdev, size=1, random_state=None)\n",
    "    return {'x': user_next, 'dx': user_next - user_last}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1267968-0195-4525-aaf8-70a804189fc7",
   "metadata": {},
   "source": [
    "### Passive Bayesian Observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595424bb-e3a1-4a49-9413-2eeeb5db6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous observation active inference agent\n",
    "# a. Belief Update agent\n",
    "\n",
    "class BayesianObserver:\n",
    "  \n",
    "  def __init__(self, model, q0_target, q0_conductivity, rng):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      model: model of the interaction between a user and an application\n",
    "      q0_target: initial belief distribution over user targets\n",
    "      q0_conductivity: initial belief distribution over the user lag parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    # config\n",
    "    self.model = model\n",
    "    self.q0_target = q0_target\n",
    "    self.q0_conductivity = q0_conductivity\n",
    "    self.rng = rng\n",
    "    \n",
    "    # state\n",
    "    self.q = None\n",
    "    \n",
    "  def copy(self):\n",
    "    other = BayesianObserver(model=self.model,\n",
    "              q0_target=self.q0_target,\n",
    "              q0_conductivity=self.q0_conductivity,\n",
    "              rng=rng)\n",
    "    \n",
    "    other.q = self.q.copy()\n",
    "    return other\n",
    "  \n",
    "  def reset(self):\n",
    "    # model is assumed to be stateless self.model.reset()\n",
    "    # initialise believe as the outer product of beliefs over individual state dimensions\n",
    "    self.q = np.outer(self.q0_conductivity, self.q0_target)\n",
    "    # return marginal distributions over individual state dimensions\n",
    "    return {'target': self.q.sum(axis=0), 'conductivity': self.q.sum(axis=1), 'q': self.q}\n",
    "            \n",
    "  def step(self, action):\n",
    "    # update user model to synchronise with observation\n",
    "    o = self.model.get_probabilities(action)\n",
    "    p_switch = o['p_switch'] # probability of the user to have switched target\n",
    "    p_o_given_s = o['p_o_given_s']\n",
    "    \n",
    "    # update belief through time\n",
    "    # - there is some chance that the user has switched their target\n",
    "    # - in this case, the new target is assumed to be distributed as per q0_target\n",
    "    # - in this case, user conductivity is assumed to remain unchanged\n",
    "    q_marginal_conductivity = self.q.sum(axis=1)\n",
    "    q_switch = np.outer(q_marginal_conductivity, self.q0_target)\n",
    "    self.q = p_switch*q_switch + (1-p_switch)*self.q\n",
    "    \n",
    "    # update belief based on new observation\n",
    "    self.q = self._update_belief(p_o_given_s)\n",
    "    return {'target': self._marginal_target(), \n",
    "            'conductivity': self._marginal_conductivity(), \n",
    "            'q': self.q}\n",
    "  \n",
    "  def sample(self):\n",
    "    k_index = self.rng.choice(self.q.shape[0], p=self._marginal_conductivity())\n",
    "    i = self.rng.choice(self.q.shape[1], p=self._conditional_target(k_index))\n",
    "    p = self.joint_probability(target=i, conductivity_index=k_index)\n",
    "    return {'target': i, \n",
    "            'conductivity_index': k_index,\n",
    "            'conductivity': self.model.k[k_index], \n",
    "            'p': p}\n",
    "    \n",
    "  def joint_probability(self, target, conductivity_index):\n",
    "    return self.q[conductivity_index, target]\n",
    "\n",
    "  def _marginal_target(self):\n",
    "    return self.q.sum(axis=0)\n",
    "  \n",
    "  def _conditional_target(self, k_index):\n",
    "    return self.q[k_index]/self.q[k_index].sum()\n",
    "  \n",
    "  def _marginal_conductivity(self):\n",
    "    return self.q.sum(axis=1)\n",
    "    \n",
    "  def _update_belief(self, p_o_given_s):\n",
    "    joint = p_o_given_s * self.q\n",
    "    return joint / joint.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59253f0-b44e-4954-a290-d1ce5b40b19f",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445b2ee-e37f-438e-b1ae-30ccc3017c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservedInteraction:\n",
    "  \n",
    "  def __init__(self, app, user):\n",
    "    self.system = Interaction(user=user, app=app)\n",
    "    \n",
    "    num_targets = app.num_targets\n",
    "    num_k =10\n",
    "    self.k = np.linspace(0.05, 0.5, num_k)\n",
    "    # use distribution over conductivity and true user noise\n",
    "    self.model =  UserModel(num_targets=num_targets, \n",
    "                            conductivity=self.k,\n",
    "                            stdev=user.noise.stdev*0.5, \n",
    "                            bounds=user.lag.bounds, p_fp=0.01, p_fn=0.01)\n",
    "    # Bayesian inference with uniform prior over targets \n",
    "    q0_target = np.ones(num_targets)/num_targets\n",
    "    q0_k = np.ones(num_k)/num_k\n",
    "    self.observer = BayesianObserver(model=self.model, \n",
    "                                     q0_target=q0_target, \n",
    "                                     q0_conductivity=q0_k, \n",
    "                                     rng=rng)\n",
    "    \n",
    "  def reset(self):\n",
    "    o = self.system.reset()\n",
    "    o['observer'] = self.observer.reset()\n",
    "    return o\n",
    "    \n",
    "  def step(self, last_state):\n",
    "    o = self.system.step(last_state)\n",
    "    o['observer'] = self.observer.step(o)\n",
    "    return o\n",
    "\n",
    "app = App(num_targets=32, \n",
    "          trigger_conductivity=0.07,\n",
    "          trigger_threshold=0.07)\n",
    "user = User(num_targets=app.num_targets, conductivity=0.25)\n",
    "system = ObservedInteraction(app=app, user=user)\n",
    "\n",
    "os = [system.reset()]\n",
    "for _ in range(1_000):\n",
    "  os.append(system.step(os[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbea387-4679-4675-8669-c45e4349c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot belief\n",
    "os_view = os\n",
    "user_k = system.system.user.lag.k\n",
    "true_user_conductivity = np.argmin(np.abs(user_k - system.k))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(3*8, 2*6))\n",
    "\n",
    "# belief about targets over time\n",
    "plt.sca(axes[0][0])\n",
    "plt.title('belief across targets over time')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('target')\n",
    "qs = [o['observer']['target'] for o in os_view]\n",
    "plt.imshow(np.array(qs).T, aspect='auto', interpolation='none')\n",
    "plt.plot([o['user']['latent']['target']['s'] for o in os_view], 'r', linewidth=1., label='true target')\n",
    "plt.legend()\n",
    "\n",
    "plt.sca(axes[1][0])\n",
    "plt.title('belief across targets over time')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('Q( target )')\n",
    "qs = [o['observer']['target'] for o in os_view]\n",
    "plt.plot(qs)\n",
    "#plt.plot([o['user']['latent']['target']['s'] for o in os_view], 'r', linewidth=1., label='true target')\n",
    "\n",
    "# belief about conductivity over time\n",
    "plt.sca(axes[0][1])\n",
    "plt.title('belief across user lag over time')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('user lag')\n",
    "plt.yticks(np.arange(system.k.shape[0]), [f\"{k:.2}\" for k in system.k])\n",
    "qs = [o['observer']['conductivity'] for o in os_view]\n",
    "plt.imshow(np.array(qs).T, aspect='auto', interpolation='none')\n",
    "plt.plot([0, len(qs)-1], [true_user_conductivity]*2, 'r', linewidth=1., label='true lag')\n",
    "plt.legend()\n",
    "\n",
    "plt.sca(axes[1][1])\n",
    "plt.title('belief across user lag over time')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('Q( user lag )')\n",
    "qs = [o['observer']['conductivity'] for o in os_view]\n",
    "plt.plot(qs)\n",
    "\n",
    "# joint instantaneous belief\n",
    "final_target = os_view[-1]['user']['latent']['target']['s']\n",
    "plt.sca(axes[0][2])\n",
    "plt.imshow(system.observer.q, aspect='auto', interpolation='none')\n",
    "plt.scatter(final_target, true_user_conductivity, marker='x', color='red', s=10**2, label='true user state')\n",
    "plt.yticks(np.arange(system.k.shape[0]), [f\"{k:.2}\" for k in system.k])\n",
    "plt.xlabel('belief over targets')\n",
    "plt.ylabel('belief over user lag')\n",
    "plt.title('belief state at the end of simulation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f1bd2-25f6-490f-bc85-6ae344ae5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Register:\n",
    "  \"\"\" Register agent. Updates the state when action is not None and returns the\n",
    "      last state on each step.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, s0=0, bounds=None):\n",
    "    self.s0 = s0\n",
    "    self.bounds = bounds\n",
    "    self.s = None # state\n",
    "    \n",
    "  def reset(self):\n",
    "    self.s = self.s0\n",
    "    self._clip()\n",
    "    return self.s\n",
    "    \n",
    "  def step(self, action=None):\n",
    "    if action is not None:\n",
    "      self.s = action\n",
    "      \n",
    "    self._clip()\n",
    "    return self.s\n",
    "  \n",
    "  def _clip(self):\n",
    "    if self.bounds is None:\n",
    "      return\n",
    "    \n",
    "    self.s = np.clip(self.s, self.bounds[0], self.bounds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498e40c-28d6-4a0f-b65c-e9a246b68dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy(os):\n",
    "  fig, ax = plt.subplots(figsize=(16, 16))\n",
    "  plt.sca(ax)\n",
    "  targets = [o['app']['latent']['trigger_in']['x'][o['user']['latent']['target']['s']] for o in os]\n",
    "  plt.plot(targets, 'y-', label='controlled system', linewidth=10, alpha=0.5)\n",
    "  es_ema = [o['app']['latent']['trigger_in']['x'] for o in os]\n",
    "  plt.plot(es_ema)\n",
    "  #energies = ([o['app']['targets']['energy'] for o in os])\n",
    "  #targets = [energies[i][os[i]['user']['latent']['target']['s']] for i in range(len(os))]\n",
    "  #plt.plot(targets, 'y-', label='controlled system', linewidth=10, alpha=0.5)\n",
    "  #plt.semilogy(energies)\n",
    "  plt.plot(np.array([o['app']['events'] for o in os])*2*app.energy_start, 'k', linewidth=1);\n",
    "\n",
    "  plt.legend()\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('smoothed energy EMA(E)')\n",
    "  plt.title('smoothed energy over time')\n",
    "  \n",
    "plot_energy([o['system'] for o in os[:300]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259ae28-65dd-4a76-8a5b-45f8cabe7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionLoop:\n",
    "  \n",
    "  def __init__(self, \n",
    "               num_targets, \n",
    "               threshold,\n",
    "               rng,\n",
    "               user_conductivity=0.1,\n",
    "               user_bounds=[-200,200],\n",
    "               user_stdev=10.):\n",
    "    self.ui = HarmonicOscillator(N=num_targets, mass=0.1, dt=0.02, energy_start=3e3, energy_max=6e3)\n",
    "    # close the loop with a first-order lag user\n",
    "    self.user_target = TargetGenerator(rng=rng, num_targets=num_targets)\n",
    "    user_lag = FirstOrderLag(conductivity=user_conductivity, bounds=user_bounds)\n",
    "    user_noise = Gaussian(stdev=user_stdev, rng=rng)\n",
    "    self.user = NoisyLag(lag=user_lag, noise=user_noise)\n",
    "    # filter energy for selection trigger\n",
    "    self.trigger_in = FirstOrderLag(conductivity=0.05, s0 = np.ones(num_targets) * self.ui.energy_start)\n",
    "    # trigger by thresholding\n",
    "    self.threshold = threshold * self.ui.energy_start\n",
    "    # Active Inference observer\n",
    "    num_k =11\n",
    "    k = np.linspace(0.0, 0.2, num_k)\n",
    "    q0_target = np.ones(num_targets)/num_targets\n",
    "    q0_k = np.ones(num_k)/num_k\n",
    "    # successive user steps are more correlated than iid Gaussian on the output -> reduce noise from observation noise\n",
    "    model = UserModel(num_targets=num_targets, \n",
    "              conductivity=k, \n",
    "              stdev=user_stdev*0.25, \n",
    "              bounds=user_bounds)\n",
    "    \n",
    "    self.observer = BayesianObserver(model=model, \n",
    "                       q0_target=q0_target, \n",
    "                       q0_conductivity=q0_k, rng=rng)\n",
    "    \n",
    "  def reset(self):\n",
    "    o = {}\n",
    "    o['ui'] = self.ui.reset()\n",
    "    o['user'] = self.user.reset()\n",
    "    o['user_target'] = self.user_target.reset()\n",
    "    o['trigger_in'] = self.trigger_in.reset()['x']\n",
    "    o['trigger_out'] = self.trigger_out(o['trigger_in'])\n",
    "    o['belief'] = self.observer.reset()\n",
    "    self.s = o\n",
    "    return self.s\n",
    "  \n",
    "  def step(self):\n",
    "    a = self.s\n",
    "    # reset UI when event has been triggered\n",
    "    if a['trigger_out'].sum() > 0:\n",
    "      self.ui.reset()\n",
    "      self.trigger_in.reset()\n",
    "\n",
    "    o = {}\n",
    "    o['ui'] = self.ui.step(a['user']['x'])\n",
    "    o['trigger_in'] = self.trigger_in.step(o['ui']['energy'])['x']\n",
    "    o['trigger_out'] = self.trigger_out(o['trigger_in'])\n",
    "\n",
    "    # resample user goal if their target has been triggered\n",
    "    o['user_target'] = self.user_target.step(a['trigger_out'])\n",
    "    o['user'] = self.user.step(o['ui']['x'][o['user_target']['s']])\n",
    "    # update observer\n",
    "    o['belief'] = self.observer.step(o)\n",
    "    self.s = o\n",
    "    return self.s\n",
    "    \n",
    "  def trigger_out(self, inputs):\n",
    "    return inputs < self.threshold\n",
    "  \n",
    "num_targets = 8\n",
    "threshold = 0.2\n",
    "num_steps = 400\n",
    "\n",
    "loop = InteractionLoop(num_targets=num_targets, threshold=threshold, rng=rng)\n",
    "os = [loop.reset()] + [loop.step() for _ in range(num_steps)]\n",
    "print(os[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c612f-b53a-4509-8de5-afbc62ad740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionLoop:\n",
    "  \n",
    "  def __init__(self, \n",
    "               num_targets, \n",
    "               threshold,\n",
    "               rng,\n",
    "               user_conductivity=0.1,\n",
    "               user_bounds=[-200,200],\n",
    "               user_stdev=10.):\n",
    "    self.ui = HarmonicOscillator(N=num_targets, mass=0.1, dt=0.02, energy_start=3e3, energy_max=6e3)\n",
    "    # close the loop with a first-order lag user\n",
    "    self.user_target = TargetGenerator(rng=rng, num_targets=num_targets)\n",
    "    user_lag = FirstOrderLag(conductivity=user_conductivity, bounds=user_bounds)\n",
    "    user_noise = Gaussian(stdev=user_stdev, rng=rng)\n",
    "    self.user = NoisyLag(lag=user_lag, noise=user_noise)\n",
    "    # filter energy for selection trigger\n",
    "    self.trigger_in = FirstOrderLag(conductivity=0.05, s0 = np.ones(num_targets) * self.ui.energy_start)\n",
    "    # trigger by thresholding\n",
    "    self.threshold = threshold * self.ui.energy_start\n",
    "    # Active Inference observer\n",
    "    num_k =11\n",
    "    k = np.linspace(0.0, 0.2, num_k)\n",
    "    q0_target = np.ones(num_targets)/num_targets\n",
    "    q0_k = np.ones(num_k)/num_k\n",
    "    # successive user steps are more correlated than iid Gaussian on the output -> reduce noise from observation noise\n",
    "    model = UserModel(num_targets=num_targets, \n",
    "              conductivity=k, \n",
    "              stdev=user_stdev*0.25, \n",
    "              bounds=user_bounds)\n",
    "    \n",
    "    self.observer = BayesianObserver(model=model, \n",
    "                       q0_target=q0_target, \n",
    "                       q0_conductivity=q0_k, rng=rng)\n",
    "    \n",
    "  def reset(self):\n",
    "    o = {}\n",
    "    o['ui'] = self.ui.reset()\n",
    "    o['user'] = self.user.reset()\n",
    "    o['user_target'] = self.user_target.reset()\n",
    "    o['trigger_in'] = self.trigger_in.reset()['x']\n",
    "    o['trigger_out'] = self.trigger_out(o['trigger_in'])\n",
    "    o['belief'] = self.observer.reset()\n",
    "    self.s = o\n",
    "    return self.s\n",
    "  \n",
    "  def step(self):\n",
    "    a = self.s\n",
    "    # reset UI when event has been triggered\n",
    "    if a['trigger_out'].sum() > 0:\n",
    "      self.ui.reset()\n",
    "      self.trigger_in.reset()\n",
    "\n",
    "    o = {}\n",
    "    o['ui'] = self.ui.step(a['user']['x'])\n",
    "    o['trigger_in'] = self.trigger_in.step(o['ui']['energy'])['x']\n",
    "    o['trigger_out'] = self.trigger_out(o['trigger_in'])\n",
    "\n",
    "    # resample user goal if their target has been triggered\n",
    "    o['user_target'] = self.user_target.step(a['trigger_out'])\n",
    "    o['user'] = self.user.step(o['ui']['x'][o['user_target']['s']])\n",
    "    # update observer\n",
    "    o['belief'] = self.observer.step(o)\n",
    "    self.s = o\n",
    "    return self.s\n",
    "    \n",
    "  def trigger_out(self, inputs):\n",
    "    return inputs < self.threshold\n",
    "  \n",
    "num_targets = 8\n",
    "threshold = 0.2\n",
    "num_steps = 400\n",
    "\n",
    "loop = InteractionLoop(num_targets=num_targets, threshold=threshold, rng=rng)\n",
    "os = [loop.reset()] + [loop.step() for _ in range(num_steps)]\n",
    "print(os[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50a5e7-6c21-4337-aa7d-9e4f9dbd566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dynamics\n",
    "os = os\n",
    "\n",
    "def plot_positions(os, ax):\n",
    "  # target positions over time\n",
    "  plt.sca(ax)\n",
    "  plt.title('target positions over time')\n",
    "  xs = np.array([o['ui']['x'] for o in os])\n",
    "  ts = np.array([o['user_target']['s'] for o in os])\n",
    "  plt.plot(xs)\n",
    "  plt.plot(xs[np.arange(ts.shape[0]),ts], 'k-', label='user target')\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('position')  \n",
    "  # user input over time\n",
    "  y = np.array([o['user']['x'] for o in os])\n",
    "  plt.plot(y, 'k--', label='user input')\n",
    "  plt.legend()\n",
    "\n",
    "def plot_velicities(os, ax):\n",
    "  # target velocity over time\n",
    "  plt.sca(ax)\n",
    "  plt.title('target velocities over time')\n",
    "  vs = np.array([o['ui']['v'] for o in os])\n",
    "  plt.plot(vs)\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('velocity')\n",
    "\n",
    "def plot_mass(os, ax):\n",
    "  # target mass over time\n",
    "  plt.sca(ax)\n",
    "  plt.title('mass over time')\n",
    "  ms = np.array([o['ui']['debug']['mass'] for o in os])\n",
    "  plt.plot(ms)\n",
    "  plt.plot(ms[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "  plt.xlabel('timestep  t')\n",
    "  plt.ylabel('mass')\n",
    "\n",
    "def plot_spring(os, ax):\n",
    "  # target spring coefficient\n",
    "  plt.sca(ax)\n",
    "  plt.title('spring coefficient over time')\n",
    "  ss = np.array([o['ui']['debug']['spring'] for o in os])\n",
    "  plt.plot(ss)\n",
    "  plt.plot(ss[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('spring coefficient')\n",
    "\n",
    "def plot_energies(os, ax):\n",
    "  # target energies\n",
    "  plt.sca(ax)\n",
    "  plt.title('energy over time')\n",
    "  es = np.array([o['ui']['energy'] for o in os])\n",
    "  plt.semilogy(es)\n",
    "  #plt.imshow(es.T, aspect='auto')\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('mechanical energy E')\n",
    "  \n",
    "def plot_trigger_input(os, ax):  \n",
    "  # trigger input over time\n",
    "  y = np.array([o['trigger_in'] for o in os])\n",
    "  plt.sca(ax)\n",
    "  plt.plot(y)\n",
    "  plt.plot([0, len(os)], [threshold]*2, 'k--', label='threshold')\n",
    "  #plt.imshow(y.T, aspect='auto')\n",
    "  plt.legend()\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('trigger input')\n",
    "  plt.title('smoothed energy over time')\n",
    "  \n",
    "def plot_trigger_output(os, ax):\n",
    "  # trigger output over time\n",
    "  y = np.array([o['trigger_out'] for o in os])\n",
    "  plt.sca(axes[7])\n",
    "  plt.plot(y)\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('trigger output')\n",
    "  plt.title('events triggered over time')\n",
    "  \n",
    "def plot_user_target(os, ax):\n",
    "  # user target\n",
    "  plt.sca(ax)\n",
    "  plt.title('user target over time')\n",
    "  ts = np.array([o['user_target']['s_one_hot'] for o in os])\n",
    "  plt.plot(ts, '--')\n",
    "  plt.xlabel('timestep t')\n",
    "  \n",
    "def plot_belief(os, ax, varname='target'):\n",
    "  # plot belief\n",
    "  plt.sca(ax)\n",
    "  plt.title('Observer belief over time')\n",
    "  qs = [o['belief'][varname] for o in os]\n",
    "  plt.imshow(np.array(qs).T, aspect='auto')\n",
    "  plt.plot([o['user_target']['s'] for o in os], 'r')\n",
    "  plt.xlabel('timestep t')\n",
    "  plt.ylabel('target id')\n",
    "  \n",
    "def plot_max_belief(os, ax, varname='target'):\n",
    "  plt.sca(ax)\n",
    "  plt.title('Observer max. belief over time')\n",
    "  qs = np.array([o['belief'][varname] for o in os])\n",
    "  plt.plot(qs.max(axis=1))\n",
    "\n",
    "num_plots = 4\n",
    "fig, axes = plt.subplots(num_plots, 1, figsize=(12, 4*num_plots))\n",
    "\n",
    "plot_positions(os, axes[0])\n",
    "#plot_velocities(os, axes[1])\n",
    "#plot_mass(os, axes[2])\n",
    "#plot_spring(os, axes[3])\n",
    "plot_energies(os, axes[1])\n",
    "plot_trigger_input(os, axes[2])\n",
    "plot_user_target(os, axes[3])\n",
    "#plot_trigger_output(os, axes[7])\n",
    "#plot_belief(os, axes[2])\n",
    "#plot_max_belief(os, axes[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop model\n",
    "class LoopModel:\n",
    "  \"\"\" Rollout of User-UI interaction in response to active inference agent actions. \"\"\"\n",
    "  \n",
    "  def __init__(self, loop, prev_obs, user_state):\n",
    "    self.loop = loop\n",
    "    self.s = prev_obs\n",
    "    self.user_state = user_state\n",
    "    \n",
    "    self.ui = loop.ui.copy()\n",
    "    self.trigger_in = loop.trigger_in.copy()\n",
    "    self.trigger_out_fn = loop.trigger_out\n",
    "    self.user_target = loop.user_target.copy()\n",
    "    self.user_target.assign(self.user_state['target']) # init user target\n",
    "    self.user_model = loop.observer.model\n",
    "    self.observer = loop.observer.copy()\n",
    "    \n",
    "    self.s = prev_obs\n",
    "    \n",
    "  def step(self, control_state=None):\n",
    "    # implement the action\n",
    "    if control_state is not None:\n",
    "      #self.ui.set_frequency(self.ui.frequency() * control_state)\n",
    "      self.ui.set_energy(self.ui.energy() * control_state)\n",
    "    \n",
    "    s = self.s\n",
    "    # propagate model through time\n",
    "    # - reset UI when event has been triggered\n",
    "    if s['trigger_out'].sum() > 0:\n",
    "      self.ui.reset()\n",
    "      self.trigger_in.reset()\n",
    "      \n",
    "    o = {}\n",
    "    o['ui'] = self.ui.step(s['user']['x'])\n",
    "    o['trigger_in'] = self.trigger_in.step(o['ui']['debug']['energy'])['x']\n",
    "    o['trigger_out'] = self.trigger_out_fn(o['trigger_in'])\n",
    "    \n",
    "    # resample user goal if their target has been triggered\n",
    "    o['user_target'] = self.user_target.step(s['trigger_out'])\n",
    "    o['user'] = s['user'] # pass last state to user for lag estimation\n",
    "    o['user'] = self.user_model.sample_action(o, self.user_state['conductivity'])\n",
    "\n",
    "    # update belief over user hidden state\n",
    "    o['belief'] = self.observer.step(o)\n",
    "    \n",
    "    self.s = o\n",
    "    return self.s\n",
    "    \n",
    "# simulate some burn in\n",
    "#os = [loop.reset()] + [loop.step() for _ in range(5)]\n",
    "    \n",
    "# construct action evaluation\n",
    "\n",
    "# setup\n",
    "num_targets = 8\n",
    "time_horizon = 100 # maximum time to consider\n",
    "delta_frequency = 0.2 # increase or decrease by x percent per step\n",
    "num_rollouts = 32\n",
    "# multiplicative control states\n",
    "num_actions = 2*num_targets+1\n",
    "us = np.ones((num_actions, num_targets))\n",
    "us = us + np.vstack([\n",
    "        np.eye(num_targets) * delta_frequency, # increase by 10%\n",
    "        np.eye(num_targets) * -delta_frequency, # decrease by 10&\n",
    "        np.zeros((1,num_targets))]) # leave unchainged\n",
    "\n",
    "print(us.shape)\n",
    "# define pragmatic value\n",
    "p_c = [0.05-1e-4, # triggered nothing\n",
    "       0.95, # triggered target\n",
    "       1e-4] # triggered the wrong\n",
    "log_p_c = np.log(p_c)\n",
    "\n",
    "# generate a set of plans repeating the same action over the time horizon\n",
    "plans = (np.arange(num_actions)[:,None] * np.ones((num_actions, time_horizon))).astype(int)\n",
    "\n",
    "# generate a set of plans, each doing nothing after the first timestep\n",
    "#first_action = np.arange(num_actions)[:,None]\n",
    "#remaining_actions = np.ones((num_actions, time_horizon-1)) * (num_actions - 1)\n",
    "#plans = np.hstack( [first_action, remaining_actions] ).astype(int)\n",
    "\n",
    "# - test concept with plan of always taking no action\n",
    "nefes = []\n",
    "for plan in plans:\n",
    "  #print(plan)\n",
    "  total_steps = 0\n",
    "  pragmatic = 0\n",
    "  \n",
    "  for _ in range(num_rollouts):\n",
    "    # - sample user state from belief distribution\n",
    "    user_state = loop.observer.sample()\n",
    "    # - rollout policy over fixed time horizon or crop if trigger occured\n",
    "    loop_model = LoopModel(loop=loop, prev_obs=os[-1], user_state=user_state)\n",
    "    q_ss = []\n",
    "    for a in plan:\n",
    "      q_ss.append(loop_model.step(us[a]))\n",
    "      if q_ss[-1]['trigger_out'].sum() > 0:\n",
    "        break\n",
    "    \n",
    "    pragmatic += (len(q_ss)-1) * log_p_c[0] # all but one timestep was not triggered\n",
    "    if q_ss[-1]['trigger_out'].sum() < 0.5:\n",
    "      pragmatic += log_p_c[0]\n",
    "    elif q_ss[-1]['trigger_out'][user_state['target']]:\n",
    "      pragmatic += log_p_c[1]\n",
    "    else:\n",
    "      pragmatic += log_p_c[2]\n",
    "      \n",
    "    total_steps += len(q_ss)\n",
    "        \n",
    "  nefes.append(pragmatic/ total_steps)\n",
    "  \n",
    "plt.plot(nefes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25749c6-083f-4102-a9f2-7ca4c7f29fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot belief\n",
    "os_view = os\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3*8, 6))\n",
    "\n",
    "# joint instantaneous belief\n",
    "plt.sca(axes[0])\n",
    "plt.imshow(loop.observer.q, aspect='auto')\n",
    "\n",
    "# belief about targets over time\n",
    "plt.sca(axes[1])\n",
    "qs = [o['belief']['target'] for o in os_view]\n",
    "plt.imshow(np.array(qs).T, aspect='auto')\n",
    "plt.plot([o['user_target']['s'] for o in os_view], 'r', label='true target')\n",
    "plt.legend()\n",
    "\n",
    "# belief about conductivity over time\n",
    "plt.sca(axes[2])\n",
    "qs = [o['belief']['conductivity'] for o in os_view]\n",
    "plt.imshow(np.array(qs).T, aspect='auto')\n",
    "plt.plot([0, len(qs)-1], [user_state['conductivity_index']]*2, 'r', label='simulated lag')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99603f-d51c-4db7-939d-e873fb13efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplicative control states\n",
    "num_actions = 2*num_targets+1\n",
    "us = np.ones((num_actions, num_targets))\n",
    "us = us + np.vstack([\n",
    "        np.eye(num_targets) * 0.1, # increase by 10%\n",
    "        np.eye(num_targets) * -0.1, # decrease by 10&\n",
    "        np.zeros((1,num_targets))]) # leave unchainged\n",
    "\n",
    "plt.imshow(us, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86af8da-58ad-4eef-95a3-a543e79a1403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "792c4710-f024-4c9b-944e-776e87f4fd5b",
   "metadata": {},
   "source": [
    "## Acting to increase pragmatic value\n",
    "\n",
    "We show how action can help to gain information about user intent and to increase the probability of observing preferred state by intervening on the mediating mechanism instead of the decision rule itself. This is in contrast to previous work such as BIGNav, which used Bayesin information gain directly for control by triggering events compatible with current belief directly. We argue that the proposed approach is more generalisable as it requires only access to the communication layer as opposed to the controlled software. It can also enable adapting faster to parameters of the user that are consistent across applications, such as touch offsets, by learning from their interaction with multiple applications.\n",
    "\n",
    "In active inference, sequences of actions (plans) are scored by the negative expected free energy, and selected by exponentiating and normalizing, i.e. sampling from the softmax over plans. Plans $\\pi: a_0, a_1, ..., a_{K-1}$ define sequences of actions up to a finite horizon of $K$ timesteps into the future. The expected free energy can be decomposed in various ways and here we chose one that we find most intuitive, involving a _pragmatic_ term and an _information gain_ term. \n",
    "\n",
    "The _pragmatic_ term assesses the probability of arriving in states following $\\pi$ that the agent desires, or of encountering observations that the agent desires. In this context, $Q_\\theta$ is estimated by propagating beliefs through the environment transition dynamics following the sequence of actions defined by $\\pi$, and observations are halucinated by sampling from the emission probability distributions.\n",
    "\n",
    "$\\mathbb{E}_{s \\sim Q_{\\theta}}\\left[\\log p_c(s)\\right] \\quad \\text{or} \\quad \\mathbb{E}_{s \\sim Q_{\\theta}, o \\sim p(o|s)}\\left[\\log p_c(o)\\right]$\n",
    "\n",
    "The _information gain_ term quantifies the belief update due to making observations in future states.\n",
    "\n",
    "$\\mathbb{E}_{s \\sim Q_{\\theta}, o \\sim p(o|s)}\\left[ D_{KL}(\\, Q_{\\theta'}(s|o),  Q_{\\theta}(s) \\,) \\right]$\n",
    "\n",
    "\n",
    "We consider actions to represent interventions on individual masses of the oscillating mechanism associated with different targets. An increase in mass increases kinetic energy and decreases the oscillation frequency, whereas a decrease in mass decreases kinetic energy and increases the oscillation frequency, respectively. A discrete action space is defined over $2N+1$ actions corresponding to no intervention, increasing, or decreasing the mass of $N$ individual targets by a fixed proportion ($\\pm10\\%$).\n",
    "\n",
    "The preferences over states and observations of an adaptive user interface could be informed by a variety of factors including the users' intent, e.g., preferring observations that are compatible with the application behaving as the user intends), the risk associated with different application states, e.g., preferring observations that are incompatible with the application being driven into unsafe states, and a policy to nudge users into preferable application states, e.g., to expose users to new features or to increase their chance of picking more healthy, more economical, or more environmentally friendly options. Because most of these factors assume some domain knowledge of the application to be meaningful, we focus here on the first, i.e. preferring observations that are compatible with user intention.\n",
    "\n",
    "### Option A: preference over trigger events\n",
    "\n",
    "Here, we define the preference distribution over observations as a function of our belief about the user's intended target and observed trigger events. Action selection thereby attempts to drive the dynamic system into a configuration that makes it easier for the user to decrease their intended target's energy, harder for the user to accidentally decrease any other target's energy, and potentially assists with energy reduction directly.\n",
    "\n",
    "One drawback of this approach is that hypothetical trigger events are sparse and we therefore need long rollouts to identify an effect\n",
    "\n",
    "### Option B: preference over energy vectors\n",
    "\n",
    "## Acting to increase information gain\n",
    "\n",
    "In order to resolve ambiguity in user intention to trigger different targets (maximising information gain) it would be useful to desynchronise those targets' movement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845571ec-b4da-49a9-8210-27bc0265c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch action mechanism\n",
    "\n",
    "# generate set of 2*N+1 discrete actions\n",
    "# control states\n",
    "us = np.vstack([\n",
    "        np.eye(num_targets) * 4, # target_value / mass_0 - 1\n",
    "        np.eye(num_targets) * -0.8, \n",
    "        np.zeros((1,num_targets))])\n",
    "\n",
    "# apply control state associated with selected action\n",
    "a = 1\n",
    "mass_pre = np.ones(num_targets)\n",
    "mass_post = mass_pre * (1 + us[a])\n",
    "plt.plot(mass_pre)\n",
    "plt.plot(mass_post)\n",
    "plt.plot(us[a])\n",
    "\n",
    "# evaluate the pragmatic value\n",
    "# - propagate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d37ce-5817-493c-ba9b-43171af47843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete action selection with pragmatic value\n",
    "\n",
    "# 1. do a rollout of the future with sampled initial target state and sampled user model parameter\n",
    "o = os[-1]\n",
    "rollout_target = rng.choice(num_targets, p=o['belief']['target'])\n",
    "rollout_conductivity = rng.choice(loop.observer.model.k, p=o['belief']['conductivity'])\n",
    "print(rollout_target, rollout_conductivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc9490-40ed-40e4-b8f5-7cae41654ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08384fcb-493b-4fc7-b512-bb4f80cebdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af66e49-c83d-410f-9828-05c90982c18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2174c47c-6032-43f2-a6d1-c5a1da4a1e4e",
   "metadata": {},
   "source": [
    "## Selection Trigger (Active Inference)\n",
    "\n",
    "In the simplest setting, we can perform belief updates using the model of the user and of the UI dynamics to reason about the user's target object.\n",
    "\n",
    "In a more advanced setting, we can intervene on the UI to help resolve ambiguity by changing some of the objects' parameters (mass, spring constant, and damping constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f56f3c-85b3-4f4a-927a-6a347dd4034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import harmonic_interaction_01 as hi\n",
    "importlib.reload(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7576c71-5b7b-4e1c-b039-40f051703a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000 * 2\n",
    "\n",
    "agents = hi.init()\n",
    "os = [hi.reset(agents)]\n",
    "for _ in range(num_steps):\n",
    "  os.append(hi.step(agents, os[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd575e9b-dd28-47e7-8f31-95dec1dc4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dynamics\n",
    "fig, axes = plt.subplots(8, 1, figsize=(12, 4*8))\n",
    "\n",
    "# target positions over time\n",
    "plt.sca(axes[0])\n",
    "plt.title('target positions over time')\n",
    "xs = np.array([o['ui']['x'] for o in os])\n",
    "ts = np.array([o['user_target']['s'] for o in os])\n",
    "plt.plot(xs)\n",
    "plt.plot(xs[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('position')\n",
    "\n",
    "# user input over time\n",
    "y = np.array([o['sim_user'] for o in os])\n",
    "plt.plot(y, 'k--', label='user input')\n",
    "plt.legend()\n",
    "\n",
    "# target velocity over time\n",
    "plt.sca(axes[1])\n",
    "plt.title('target velocities over time')\n",
    "vs = np.array([o['ui']['v'] for o in os])\n",
    "plt.plot(vs)\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('velocity')\n",
    "\n",
    "# target mass\n",
    "plt.sca(axes[2])\n",
    "plt.title('mass over time')\n",
    "ms = np.array([o['ui']['debug']['mass'] for o in os])\n",
    "plt.plot(ms)\n",
    "plt.plot(ms[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "plt.xlabel('timestep  t')\n",
    "plt.ylabel('mass')\n",
    "\n",
    "# target spring coefficient\n",
    "plt.sca(axes[3])\n",
    "plt.title('spring coefficient over time')\n",
    "ss = np.array([o['ui']['debug']['spring'] for o in os])\n",
    "plt.plot(ss)\n",
    "plt.plot(ss[np.arange(num_steps+1),ts], 'k-', label='user target')\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('spring coefficient')\n",
    "\n",
    "# target energies\n",
    "plt.sca(axes[4])\n",
    "plt.title('energy over time')\n",
    "es = np.array([o['ui']['debug']['energy'] for o in os])\n",
    "plt.plot(es)\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('mechanical energy E')\n",
    "\n",
    "# user target\n",
    "plt.sca(axes[5])\n",
    "plt.title('user target over time')\n",
    "ts = np.array([o['user_target']['s_one_hot'] for o in os])\n",
    "plt.plot(ts, '--')\n",
    "plt.xlabel('timestep t')\n",
    "\n",
    "# trigger output over time\n",
    "y = np.array([o['trigger_out'] for o in os])\n",
    "plt.sca(axes[6])\n",
    "plt.plot(y)\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('trigger output')\n",
    "plt.title('events triggered over time')\n",
    "\n",
    "# trigger input over time\n",
    "y = np.array([o['trigger_in'] for o in os])\n",
    "plt.sca(axes[7])\n",
    "plt.plot(y)\n",
    "plt.plot([0, len(os)], [threshold]*2, 'k--', label='threshold')\n",
    "plt.legend()\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('trigger input')\n",
    "plt.title('smoothed energy over time')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23c165-f607-4148-8194-a4972ad4328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = Register(s0=0, bounds=[0.2, 0.8])\n",
    "display(user.reset())\n",
    "display(user.step())\n",
    "display(user.step(2.))\n",
    "display(user.step())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6423e10-6fec-4ee3-9006-7df6f78af83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9820437-5d67-48e9-a562-7f2be6839c26",
   "metadata": {},
   "source": [
    "# Legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6d4bf-b14d-43fd-8f11-b3a2b7ba5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. reason about user intent by observing interaction\n",
    "\n",
    "# a. traditional approach: moving average velocity below threshold, with\n",
    "# initial value, capcity (moving average weight) and threshold finetuned\n",
    "# tie-break on value if threshold is crossed by multiple targets\n",
    "# - fine-tune initial value to maximum peak velocity\n",
    "# - fine-tune conductivity to reduce oscillation in controlled object's score\n",
    "#   near convergence\n",
    "# - fine-tune threshold to separate controlled from uncontrolled objects\n",
    "# - trigger action if a single object's score is below threshold\n",
    "\n",
    "num_objects = 16\n",
    "num_steps = 200\n",
    "fig, ax = plt.subplots(figsize=(8*2, 12))\n",
    "\n",
    "mass = np.ones(num_objects) + np.linspace(0, 1, num_objects)\n",
    "ui = MassSpringDamper(mass=mass, bounds=[-1, 1])\n",
    "user = FirstOrderLag(conductivity=0.1)\n",
    "\n",
    "reasoner = FirstOrderLag(conductivity=0.05, s0=0.1)\n",
    "#reasoner = SimpleMovingAverage(buffer_size=64, s0=np.ones(num_objects)*0.02)\n",
    "threshold = 0.001\n",
    "\n",
    "os_ui = []\n",
    "os_user = []\n",
    "ss_reasoner = []\n",
    "os_reasoner = []\n",
    "\n",
    "user.reset()\n",
    "reasoner.reset()\n",
    "o_ui = ui.reset()\n",
    "\n",
    "for _ in range(num_steps):\n",
    "  # stimulus response - target system at index 0\n",
    "  o_user = user.step(o_ui['x'][-1])\n",
    "  # log stimulus and response\n",
    "  os_ui.append(o_ui['x'])\n",
    "  os_user.append(o_user)\n",
    "  # simulate next stimulus\n",
    "  o_ui = ui.step(o_user)\n",
    "  # reason about ui response to user input\n",
    "  s_reasoner = reasoner.step(np.abs(o_ui['dx']))\n",
    "  o_reasoner = s_reasoner < threshold\n",
    "  ss_reasoner.append(s_reasoner)\n",
    "  os_reasoner.append(o_reasoner)\n",
    "  \"\"\"\n",
    "  if np.sum(o_reasoner > 1e-6):\n",
    "    # object selected\n",
    "    break\n",
    "  \"\"\"\n",
    "  \n",
    "plt.plot(ss_reasoner, '-');\n",
    "plt.plot(np.max(np.array(os_reasoner), axis=1) * np.max(ss_reasoner), 'k-', label='triggered');\n",
    "plt.plot([0, num_steps], [threshold, threshold], 'k--', label='threshold');\n",
    "plt.xlabel('timestep t')\n",
    "plt.ylabel('selection score (lower is better)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578373ad-07cc-4011-8b93-334dde49d632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_inference]",
   "language": "python",
   "name": "conda-env-active_inference-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
